{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "588ec3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "import ds_utils_callum\n",
    "import priv_policy_manipulation_functions as priv_pol_funcs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2182b009",
   "metadata": {},
   "source": [
    "Story et al. (2019) \"Natural Language Processing for Mobile App Privacy Compliance\", available from https://usableprivacy.org/publications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab3f4a4",
   "metadata": {},
   "source": [
    "# Confirm all cells are strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "fc7245da",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_segment_annots_df = pd.read_pickle('segment_annots_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "6b93e148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def column_all_dtype(dataframe_column, dtype):\n",
    "    \"\"\"\n",
    "    Example inputs for dtype: str, \"<class 'numpy.int64'>\", \"<class 'numpy.bool_'>\"\n",
    "    \"\"\"\n",
    "    for _index in range(len(dataframe_column)):\n",
    "        if str(type(dataframe_column[_index])) != str(dtype):\n",
    "            return False\n",
    "    return True\n",
    "# validation on columns of known type:\n",
    "print(column_all_dtype(clean_segment_annots_df['policy_segment_id'], \"<class 'numpy.int64'>\") ) # should return True\n",
    "print(column_all_dtype(clean_segment_annots_df['policy_segment_id'], str) ) # should return False\n",
    "print(column_all_dtype(clean_segment_annots_df['contains_synthetic'], \"<class 'numpy.bool_'>\") ) # should return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3461083f",
   "metadata": {},
   "source": [
    "Confirming all segment text is str:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "3f2e7298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_all_dtype(clean_segment_annots_df['segment_text'], str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3582f563",
   "metadata": {},
   "source": [
    "# Normalize Whitespace\n",
    "\n",
    "Using `new_string = \" \".join(old_string.split())`.  The `.split()` function considers a range of forms of whitespace.\n",
    "\n",
    "I want to check the length of all the text before and after to see any difference made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "daa73d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check total length\n",
    "def total_length(dataframe):\n",
    "    total_length_all_segments = 0\n",
    "    for _index in range(len(dataframe)):\n",
    "        total_length_all_segments += len(dataframe.at[_index, \"segment_text\"])\n",
    "    return f\"Total length of all segments is {total_length_all_segments}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "5c38cad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_whitespace(dataframe):\n",
    "    \"\"\"\n",
    "    Removed whitespace from all cells in the \"segment_text\" column.\n",
    "    For verification, prints the total segment length before and after.\n",
    "    Input: Dataframe with a column called \"segment_text\" that contains strings for the whitespace to be removed.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(total_length(dataframe))\n",
    "    \n",
    "    # normalize whitespace\n",
    "    for _index in range(len(dataframe)):\n",
    "        dataframe.at[_index, \"segment_text\"] = \" \".join(dataframe.at[_index, \"segment_text\"].split())\n",
    "    \n",
    "    #verify change\n",
    "    print(total_length(dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "237aefe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of all segments is 5917918\n",
      "Total length of all segments is 5917918\n"
     ]
    }
   ],
   "source": [
    "normalize_whitespace(clean_segment_annots_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7b13ac",
   "metadata": {},
   "source": [
    "Suspiciously nothing changed, so I will verify my function before concluding that the privacy policy segments have no whitespace in them.\n",
    "\n",
    "Verifying the function by testing it on some whitespace.\n",
    "- create  a dataframe where I have intentionally added whitespace \n",
    "- calling the function on this dataframe\n",
    "- confirming the whitespace is removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "65180163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of all segments is 5917320\n",
      "Total length of all segments is 5917279\n"
     ]
    }
   ],
   "source": [
    "text_with_space = 'PRIVACY                                          This.'\n",
    "verify_whitespace_df = clean_segment_annots_df.copy()\n",
    "verify_whitespace_df.loc[0, 'segment_text'] = text_with_space\n",
    "normalize_whitespace(verify_whitespace_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76088696",
   "metadata": {},
   "source": [
    "I have verified that my function works and so can conclude that the privacy policy segments have no whitespace in them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66297e7a",
   "metadata": {},
   "source": [
    "# Normalize punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33013da4",
   "metadata": {},
   "source": [
    "First let's investigate whether are any unusual characters that could "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cd5e24",
   "metadata": {},
   "source": [
    "I took the below function from this towardsdatascience article [here](https://towardsdatascience.com/text-normalization-7ecc8e084e31)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "69da5a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _simplify_punctuation(text):\n",
    "    \"\"\"\n",
    "    This function simplifies doubled or more complex punctuation. The exception is '...'.\n",
    "    \"\"\"\n",
    "    \n",
    "    corrected = str(text)\n",
    "    corrected = re.sub(r'([!?,;])\\1+', r'\\1', corrected)\n",
    "    corrected = re.sub(r'\\.{2,}', r'...', corrected)\n",
    "    return corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "a7ef8ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_punctuation(dataframe):\n",
    "    print(total_length(dataframe))\n",
    "    for _index in range(len(dataframe)):\n",
    "        dataframe.at[_index, \"segment_text\"] = _simplify_punctuation(dataframe.at[_index, \"segment_text\"])\n",
    "    print(total_length(dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "1d209643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of all segments is 5917918\n",
      "Total length of all segments is 5917879\n"
     ]
    }
   ],
   "source": [
    "remove_duplicate_punctuation(clean_segment_annots_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614dd1da",
   "metadata": {},
   "source": [
    "Only a small number of characters were removed as expected.\n",
    "\n",
    "Further punctuation normalization such as converting other characters to their english standardized versions (e.g. the opening speachmark “ to \", or elipses … to ...) would be ideal, but the ommission of this should not affect the sentence filtering much, and won't have any effect on the tf-idf matrix, because it ignores punctuation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a20351",
   "metadata": {},
   "source": [
    "# Remove non-ASCII characters\n",
    "\n",
    "This can be done by checking whether each character has a unicode index below 128, as ASCII characters are coded above 128.  Checking the unicode 'code point' is done with `ord(char)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "e4a7aadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc\n",
      "a_b^0\n"
     ]
    }
   ],
   "source": [
    "def remove_non_ascii(string):\n",
    "    \"\"\"\n",
    "    I found this function on this website: https://bobbyhadz.com/blog/python-remove-non-ascii-characters-from-string\n",
    "    \"\"\"\n",
    "    return ''.join(char for char in string if ord(char) < 128)\n",
    "\n",
    "# demonstrate function:\n",
    "print(remove_non_ascii('a€bñcá')) # >> 'abc'\n",
    "print(remove_non_ascii('a_b^0')) # >> a_b^0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "91f16ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nonASCII_chars(dataframe):\n",
    "    print(total_length(dataframe))\n",
    "    for _index in range(len(dataframe)):\n",
    "        dataframe.at[_index, \"segment_text\"] = remove_non_ascii(dataframe.at[_index, \"segment_text\"])\n",
    "    print(total_length(dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "bbd8b58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of all segments is 5917879\n",
      "Total length of all segments is 5901658\n"
     ]
    }
   ],
   "source": [
    "remove_nonASCII_chars(clean_segment_annots_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71dbcec",
   "metadata": {},
   "source": [
    "Thousands of characters were removed, representing nearly .3% of all characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c635d39",
   "metadata": {},
   "source": [
    "# Make all policy text lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "5f53e223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ifiufiwunfiijnf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      segment_text\n",
       "0  ifiufiwunfiijnf"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convert_to_lowercase(dataframe):\n",
    "\n",
    "    for _index in range(len(dataframe)):\n",
    "        dataframe.at[_index, \"segment_text\"] = dataframe.at[_index, \"segment_text\"].lower()\n",
    "\n",
    "# verify\n",
    "sample_df = pd.DataFrame([\"ifiUFIWUNFIijnf\"], columns=[\"segment_text\"])\n",
    "convert_to_lowercase(sample_df)\n",
    "display(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "6ae5487b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    privacy policy this privacy policy (hereafter ...\n",
       "1    1. about our products 1.1 our products offer a...\n",
       "2    2. the information we collect the information ...\n",
       "Name: segment_text, dtype: object"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_to_lowercase(clean_segment_annots_df)\n",
    "clean_segment_annots_df['segment_text'].head(3) # verify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd5d06c",
   "metadata": {},
   "source": [
    "It can be seen that the text has been changed to lowercase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1490337",
   "metadata": {},
   "source": [
    "**Save the above result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "22ab7ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_segment_annots_df.to_pickle('clean_segment_annots_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a4297a",
   "metadata": {},
   "source": [
    "# Same pre-processing steps for Annotation Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8068c7cd",
   "metadata": {},
   "source": [
    "When populating the dataframe with crafted features, the dataframe of `annotation features` will be referred to, but it is possible that it is not formatted in the same way, so I will check the format of that too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150ab664",
   "metadata": {},
   "source": [
    "I doubt it will have any non-ASCII characters so I will just check which non-lowercase letters there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "8500382c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "579"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the list of all the crafted features\n",
    "annotation_features = pd.read_pickle('annotation_features.pkl')\n",
    "list_all_crafted_features = [feature for row in annotation_features['features'] for feature in row]\n",
    "len(list_all_crafted_features) # verify – should be 579 crafted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "79ee3520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '.', ',', '-', '\\xa0', '/', 'S', 'N', 'U', 'T', 'P', 'A', '(', ')', 'I', \"'\"]\n"
     ]
    }
   ],
   "source": [
    "list_of_chars = []\n",
    "for ft in list_all_crafted_features:\n",
    "    for char in ft:\n",
    "        if char not in \"abcdefghijklmnopqrstuvwxyz\":\n",
    "            if char not in list_of_chars:\n",
    "                list_of_chars.append(char)\n",
    "print(list_of_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a959fefc",
   "metadata": {},
   "source": [
    "By inspecting this list I can see that the only characters that I don't expect are the uppercase letters and \"\\xa0\", which represents a type of whitespace."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb541a76",
   "metadata": {},
   "source": [
    "I also noticed while manually browsing the features that Bluetooth was not listed because it had been incorrectly entered as 'bluethooth', so I will correct that now too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "2bb04d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_all_crafted_features = [feature for row in annotation_features['features'] for feature in row]\n",
    "\"bluethooth\" in list_all_crafted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "6587fad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _row in range(len(annotation_features)):\n",
    "    crafted_feature_list = annotation_features.at[_row, 'features']\n",
    "\n",
    "    new_crafted_feature_list = [\"bluetooth\" if feature==\"bluethooth\" else feature for feature in crafted_feature_list]\n",
    "    new_crafted_feature_list = [feature.lower() for feature in new_crafted_feature_list]\n",
    "    new_crafted_feature_list = [\" \".join(feature.split()) for feature in new_crafted_feature_list]\n",
    "\n",
    "    \n",
    "    annotation_features.at[_row, 'features'] = new_crafted_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "e9afbe58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_all_crafted_features = [feature for row in annotation_features['features'] for feature in row]\n",
    "\"bluethooth\" in list_all_crafted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "ae166c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' ', '.', ',', '-', '/', '(', ')', \"'\"]"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(list_all_crafted_features)) # verify – should be 579 crafted features\n",
    "list_of_chars = []\n",
    "for ft in list_all_crafted_features:\n",
    "    for character in ft:\n",
    "        if character not in \"abcdefghijklmnopqrstuvwxyz\":\n",
    "            if character not in list_of_chars:\n",
    "                list_of_chars.append(character)\n",
    "list_of_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2875e0e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9154dda9",
   "metadata": {},
   "source": [
    "All problematic characters are now removed so this list of features can be used for modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "12c2b836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "annotation_features.to_pickle('clean_annotation_features.pkl')\n",
    "confirm_save_0 = pd.read_pickle('clean_annotation_features.pkl')\n",
    "print(annotation_features.shape == confirm_save_0.shape)\n",
    "print(confirm_save_0.equals(annotation_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6284f80",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f20e7c1",
   "metadata": {},
   "source": [
    "# Append annotation features to dataframe\n",
    "\n",
    "The next steps are to:\n",
    "- 1. Append each feature as a column to the dataframe with the annotation as a prefix\n",
    "- 2. Populate the columns using the segment\n",
    "\n",
    "Then I can move to modelling.\n",
    "\n",
    "I already have a function to help with 1 called `add_empty_annotation_columns`.  I just need to put the new features into a list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b24ec8",
   "metadata": {},
   "source": [
    "First I want to check whether any of the features are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "a54cd64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_annotation_features = pd.read_pickle('clean_annotation_features.pkl')\n",
    "clean_segment_annots_df = pd.read_pickle('clean_segment_annots_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "c4541c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_all_crafted_features = [feature for row in clean_annotation_features['features'] for feature in row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "0b0ae5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features = []\n",
    "duplicate_features = []\n",
    "for feature in list_all_crafted_features:\n",
    "    if feature in all_features:\n",
    "        duplicate_features.append(feature)\n",
    "    all_features.append(feature)\n",
    "len(duplicate_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b4ede5",
   "metadata": {},
   "source": [
    "Hmm a lot of the features are exactly the same.  I'm not sure that this will be an issue though – the only step being done while a dataframe with multiple same column names is populating it, which I can do by looping through the columns one at a time, but this will be worth keeping in mind.  Ideally I would clean it up as some pandas functions are unavailable if the dataframe has multiple column names with the same name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d3b184",
   "metadata": {},
   "source": [
    "## Add crafted features columns to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "8c8680a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579\n",
      "(15543, 41)\n",
      "The shape of the returned dataframe is (15543, 620)\n"
     ]
    }
   ],
   "source": [
    "print(len(list_all_crafted_features))\n",
    "print(clean_segment_annots_df.shape)\n",
    "crafted_features_df = priv_pol_funcs.add_empty_annotation_columns(clean_segment_annots_df, list_all_crafted_features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "d8edacbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NOT_PERFORMED</th>\n",
       "      <th>contact info</th>\n",
       "      <th>contact details</th>\n",
       "      <th>contact data</th>\n",
       "      <th>e.g., your name</th>\n",
       "      <th>contact you</th>\n",
       "      <th>your contact</th>\n",
       "      <th>identify, contact</th>\n",
       "      <th>identifying information</th>\n",
       "      <th>your name, address, and e-mail address</th>\n",
       "      <th>...</th>\n",
       "      <th>never be acquired</th>\n",
       "      <th>never be viewed</th>\n",
       "      <th>never be located</th>\n",
       "      <th>never be asked</th>\n",
       "      <th>never be utilized</th>\n",
       "      <th>never be requested</th>\n",
       "      <th>never be transmitted</th>\n",
       "      <th>never be communicated</th>\n",
       "      <th>nor do we collect</th>\n",
       "      <th>does not tell us</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 580 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NOT_PERFORMED  contact info  contact details  contact data  \\\n",
       "0              0             0                0             0   \n",
       "1              0             0                0             0   \n",
       "\n",
       "   e.g., your name  contact you  your contact  identify, contact  \\\n",
       "0                0            0             0                  0   \n",
       "1                0            0             0                  0   \n",
       "\n",
       "   identifying information  your name, address, and e-mail address  ...  \\\n",
       "0                        0                                       0  ...   \n",
       "1                        0                                       0  ...   \n",
       "\n",
       "   never be acquired  never be viewed  never be located  never be asked  \\\n",
       "0                  0                0                 0               0   \n",
       "1                  0                0                 0               0   \n",
       "\n",
       "   never be utilized  never be requested  never be transmitted  \\\n",
       "0                  0                   0                     0   \n",
       "1                  0                   0                     0   \n",
       "\n",
       "   never be communicated  nor do we collect  does not tell us  \n",
       "0                      0                  0                 0  \n",
       "1                      0                  0                 0  \n",
       "\n",
       "[2 rows x 580 columns]"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crafted_features_df.iloc[:,40:].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639ff022",
   "metadata": {},
   "source": [
    "We can see that the crafted features are all columns from column 41 to the end.  Now let's remove the duplicate feature columns before populating them all. I expect 103 columns to be removed to bring the `crafted_features_df` down to 517 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "d48c302e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15543, 517)"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crafted_features_df = crafted_features_df.loc[:,~crafted_features_df.columns.duplicated()] # remove columns with duplicate names\n",
    "crafted_features_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e10e71",
   "metadata": {},
   "source": [
    "To populate the crafted features columns, I will:\n",
    "\n",
    "- Take the column name for each crafted feature\n",
    "- take the segment text for each row\n",
    "- if column name in segment text: put 1.\n",
    "\n",
    "**This may take some time to run!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "df312cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.1 s, sys: 188 ms, total: 28.3 s\n",
      "Wall time: 28.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "all_rows = range(len(crafted_features_df)) # index of rows to loop through\n",
    "\n",
    "for column_number in range(41, 517): # Looping through each column with a feature\n",
    "\n",
    "    column_name = crafted_features_df.columns[column_number] # for that column feature\n",
    "\n",
    "    for row in all_rows: # and for every row\n",
    "        if column_name in crafted_features_df.at[row, \"segment_text\"]: # if the segment has that feature\n",
    "            crafted_features_df.at[row, column_name] = 1 # make the value for that feature on that row equal 1\n",
    "    \n",
    "    print(f\"Processing {column_number}/517\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "38fdf3f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133 features have not been populated\n"
     ]
    }
   ],
   "source": [
    "# looking at some of the results to verify\n",
    "summations = crafted_features_df.iloc[:,41:].sum()\n",
    "print(f\"{(summations==0).sum()} features have not been populated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91616fda",
   "metadata": {},
   "source": [
    "This seems like a lot of empty columns, so I manually looked through the results, as well as checking the source text, and found that most of the crafted feature columns that haven't been populated are generally:\n",
    "- unusual ways of typing a phrase (example: 'post code' instead of postcode)\n",
    "- specific phrases for uncommon data practices (example: 'exact device location')\n",
    "- negative phrases (example: never be requested)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbce4bd",
   "metadata": {},
   "source": [
    "Overall this looks roughly correct so I will use it for modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e532f1",
   "metadata": {},
   "source": [
    "## Saving the df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434c4a83",
   "metadata": {},
   "source": [
    "As before, to make it faster to load this dataframe in this notebook and others, I will save this dataframe as a pickle file.  This allows the below code to be ran without waiting for the above code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "e9c64479",
   "metadata": {},
   "outputs": [],
   "source": [
    "crafted_features_df.to_pickle('crafted_features_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f18817",
   "metadata": {},
   "source": [
    "Verifying that the file was correctly saved and can be imported properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "39a25967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "confirm_save_5 = pd.read_pickle('crafted_features_df.pkl')\n",
    "print(crafted_features_df.shape == confirm_save_5.shape)\n",
    "print(confirm_save_5.equals(crafted_features_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a15df1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "priv_pol_nlp",
   "language": "python",
   "name": "priv_pol_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
