{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "588ec3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "import ds_utils_callum\n",
    "import priv_policy_manipulation_functions as priv_pol_funcs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2182b009",
   "metadata": {},
   "source": [
    "Story et al. (2019) \"Natural Language Processing for Mobile App Privacy Compliance\", available from https://usableprivacy.org/publications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974f1c9b",
   "metadata": {},
   "source": [
    "# Confirm all cells are strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc10e17",
   "metadata": {},
   "source": [
    "# Read in a different df and name it something else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "14aa869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "crafted_features_df = pd.read_pickle('crafted_features_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8dda1cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def column_all_dtype(dataframe_column, dtype):\n",
    "    \"\"\"\n",
    "    Example inputs for dtype: str, \"<class 'numpy.int64'>\", \"<class 'numpy.bool_'>\"\n",
    "    \"\"\"\n",
    "    for _index in range(len(dataframe_column)):\n",
    "        if str(type(dataframe_column[_index])) != str(dtype):\n",
    "            return False\n",
    "    return True\n",
    "# validation on columns of known type:\n",
    "print(column_all_dtype(crafted_features_df['policy_segment_id'], \"<class 'numpy.int64'>\") ) # should return True\n",
    "print(column_all_dtype(crafted_features_df['policy_segment_id'], str) ) # should return False\n",
    "print(column_all_dtype(crafted_features_df['contains_synthetic'], \"<class 'numpy.bool_'>\") ) # should return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52b77ed",
   "metadata": {},
   "source": [
    "Confirming all segment text is str:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "26cd1535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_all_dtype(crafted_features_df['segment_text'], str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3582f563",
   "metadata": {},
   "source": [
    "# Normalize Whitespace\n",
    "\n",
    "Using `new_string = \" \".join(old_string.split())`.  The `.split()` function considers a range of forms of whitespace.\n",
    "\n",
    "I want to check the length of all the text before and after to see any difference made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "cf4f47db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check total length\n",
    "def total_length(dataframe):\n",
    "    total_length_all_segments = 0\n",
    "    for _index in range(len(dataframe)):\n",
    "        total_length_all_segments += len(dataframe.at[_index, \"segment_text\"])\n",
    "    return f\"Total length of all segments is {total_length_all_segments}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "23afde21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_whitespace(dataframe):\n",
    "    \"\"\"\n",
    "    Removed whitespace from all cells in the \"segment_text\" column.\n",
    "    For verification, prints the total segment length before and after.\n",
    "    Input: Dataframe with a column called \"segment_text\" that contains strings for the whitespace to be removed.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(total_length(dataframe))\n",
    "    \n",
    "    # normalize whitespace\n",
    "    for _index in range(len(dataframe)):\n",
    "        dataframe.at[_index, \"segment_text\"] = \" \".join(dataframe.at[_index, \"segment_text\"].split())\n",
    "    \n",
    "    #verify change\n",
    "    print(total_length(dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "12635190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of all segments is 5917918\n",
      "Total length of all segments is 5917918\n"
     ]
    }
   ],
   "source": [
    "normalize_whitespace(crafted_features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e29aec5",
   "metadata": {},
   "source": [
    "Suspiciously nothing changed, so I will verify my function before concluding that the privacy policy segments have no whitespace in them.\n",
    "\n",
    "Verifying the function by testing it on some whitespace.\n",
    "- create  a dataframe where I have intentionally added whitespace \n",
    "- calling the function on this dataframe\n",
    "- confirming the whitespace is removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b527804c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of all segments is 5917320\n",
      "Total length of all segments is 5917279\n"
     ]
    }
   ],
   "source": [
    "text_with_space = 'PRIVACY                                          This.'\n",
    "verify_whitespace_df = crafted_features_df.copy()\n",
    "verify_whitespace_df.loc[0, 'segment_text'] = text_with_space\n",
    "normalize_whitespace(verify_whitespace_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78dc887",
   "metadata": {},
   "source": [
    "I have verified that my function works and so can conclude that the privacy policy segments have no whitespace in them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2438dc26",
   "metadata": {},
   "source": [
    "# Normalize punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a6603b",
   "metadata": {},
   "source": [
    "First let's investigate whether are any unusual characters that could "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce4d980",
   "metadata": {},
   "source": [
    "I took the below function from this towardsdatascience article [here](https://towardsdatascience.com/text-normalization-7ecc8e084e31)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "dee048eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _simplify_punctuation(text):\n",
    "    \"\"\"\n",
    "    This function simplifies doubled or more complex punctuation. The exception is '...'.\n",
    "    \"\"\"\n",
    "    \n",
    "    corrected = str(text)\n",
    "    corrected = re.sub(r'([!?,;])\\1+', r'\\1', corrected)\n",
    "    corrected = re.sub(r'\\.{2,}', r'...', corrected)\n",
    "    return corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "13de98e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_punctuation(dataframe):\n",
    "    print(total_length(dataframe))\n",
    "    for _index in range(len(dataframe)):\n",
    "        dataframe.at[_index, \"segment_text\"] = _simplify_punctuation(dataframe.at[_index, \"segment_text\"])\n",
    "    print(total_length(dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "bb13e27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of all segments is 5917918\n",
      "Total length of all segments is 5917879\n"
     ]
    }
   ],
   "source": [
    "remove_duplicate_punctuation(crafted_features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0ff00a",
   "metadata": {},
   "source": [
    "Only a small number of characters were removed as expected.\n",
    "\n",
    "Further punctuation normalization such as converting other characters to their english standardized versions (e.g. the opening speachmark “ to \", or elipses … to ...) would be ideal, but the ommission of this should not affect the sentence filtering much, and won't have any effect on the tf-idf matrix, because it ignores punctuation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c361528f",
   "metadata": {},
   "source": [
    "# Remove non-ASCII characters\n",
    "\n",
    "This can be done by checking whether each character has a unicode index below 128, as ASCII characters are coded above 128.  Checking the unicode 'code point' is done with `ord(char)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "21428652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc\n",
      "a_b^0\n"
     ]
    }
   ],
   "source": [
    "def remove_non_ascii(string):\n",
    "    \"\"\"\n",
    "    I found this function on this website: https://bobbyhadz.com/blog/python-remove-non-ascii-characters-from-string\n",
    "    \"\"\"\n",
    "    return ''.join(char for char in string if ord(char) < 128)\n",
    "\n",
    "# demonstrate function:\n",
    "print(remove_non_ascii('a€bñcá')) # >> 'abc'\n",
    "print(remove_non_ascii('a_b^0')) # >> a_b^0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "15e443e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nonASCII_chars(dataframe):\n",
    "    print(total_length(dataframe))\n",
    "    for _index in range(len(dataframe)):\n",
    "        dataframe.at[_index, \"segment_text\"] = remove_non_ascii(dataframe.at[_index, \"segment_text\"])\n",
    "    print(total_length(dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "2830005f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of all segments is 5917879\n",
      "Total length of all segments is 5901658\n"
     ]
    }
   ],
   "source": [
    "remove_nonASCII_chars(crafted_features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cf037f",
   "metadata": {},
   "source": [
    "Thousands of characters were removed, representing nearly .3% of all characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7be5fe",
   "metadata": {},
   "source": [
    "# Make all policy text lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "884cbbcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ifiufiwunfiijnf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      segment_text\n",
       "0  ifiufiwunfiijnf"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convert_to_lowercase(dataframe):\n",
    "\n",
    "    for _index in range(len(dataframe)):\n",
    "        dataframe.at[_index, \"segment_text\"] = dataframe.at[_index, \"segment_text\"].lower()\n",
    "\n",
    "# verify\n",
    "sample_df = pd.DataFrame([\"ifiUFIWUNFIijnf\"], columns=[\"segment_text\"])\n",
    "convert_to_lowercase(sample_df)\n",
    "display(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e013b188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    privacy policy this privacy policy (hereafter ...\n",
       "1    1. about our products 1.1 our products offer a...\n",
       "2    2. the information we collect the information ...\n",
       "Name: segment_text, dtype: object"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_to_lowercase(crafted_features_df)\n",
    "crafted_features_df['segment_text'].head(3) # verify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6111114a",
   "metadata": {},
   "source": [
    "It can be seen that the text has been changed to lowercase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4a5e60",
   "metadata": {},
   "source": [
    "# Same pre-processing steps for Annotation Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112c79e8",
   "metadata": {},
   "source": [
    "When populating the dataframe with crafted features, the dataframe of `annotation features` will be referred to, but it is possible that it is not formatted in the same way, so I will check the format of that too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f014d86",
   "metadata": {},
   "source": [
    "I doubt it will have any non-ASCII characters so I will just check which non-lowercase letters there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "13471f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "579"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the list of all the crafted features\n",
    "annotation_features = pd.read_pickle('annotation_features.pkl')\n",
    "list_all_crafted_features = [feature for row in annotation_features['features'] for feature in row]\n",
    "len(list_all_crafted_features) # verify – should be 579 crafted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a0720766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '.', ',', '-', '\\xa0', '/', 'S', 'N', 'U', 'T', 'P', 'A', '(', ')', 'I', \"'\"]\n"
     ]
    }
   ],
   "source": [
    "list_of_chars = []\n",
    "for ft in list_all_crafted_features:\n",
    "    for char in ft:\n",
    "        if char not in \"abcdefghijklmnopqrstuvwxyz\":\n",
    "            if char not in list_of_chars:\n",
    "                list_of_chars.append(char)\n",
    "print(list_of_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2836e940",
   "metadata": {},
   "source": [
    "By inspecting this list I can see that the only characters that I don't expect are the uppercase letters and \"\\xa0\", which represents a type of whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "08728453",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _row in range(len(annotation_features)):\n",
    "    crafted_feature_list = annotation_features.at[_row, 'features']\n",
    "    \n",
    "    new_crafted_feature_list = [feature.lower() for feature in crafted_feature_list]\n",
    "    new_crafted_feature_list = [\" \".join(feature.split()) for feature in new_crafted_feature_list]\n",
    "    \n",
    "    annotation_features.at[_row, 'features'] = new_crafted_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "51eff510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' ', '.', ',', '-', '/', '(', ')', \"'\"]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_all_crafted_features = [feature for row in annotation_features['features'] for feature in row]\n",
    "print(len(list_all_crafted_features)) # verify – should be 579 crafted features\n",
    "list_of_chars = []\n",
    "for ft in list_all_crafted_features:\n",
    "    for character in ft:\n",
    "        if character not in \"abcdefghijklmnopqrstuvwxyz\":\n",
    "            if character not in list_of_chars:\n",
    "                list_of_chars.append(character)\n",
    "list_of_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d44223e",
   "metadata": {},
   "source": [
    "All problematic characters are now removed so this list of features can be used for modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "876b32b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "annotation_features.to_pickle('clean_annotation_features.pkl')\n",
    "confirm_save_0 = pd.read_pickle('clean_annotation_features.pkl')\n",
    "print(annotation_features.shape == confirm_save_0.shape)\n",
    "print(confirm_save_0.equals(annotation_features))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "priv_pol_nlp",
   "language": "python",
   "name": "priv_pol_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
