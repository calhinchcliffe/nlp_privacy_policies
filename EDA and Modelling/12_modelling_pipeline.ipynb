{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb32d037",
   "metadata": {},
   "source": [
    "In this notebook:\n",
    "\n",
    "Modelling pipeline: grid search over all classes.\n",
    "\n",
    "Then to make bigrams and sentence filtering optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86a733d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "import sys\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "import ds_utils_callum\n",
    "import priv_policy_manipulation_functions as priv_pol_funcs\n",
    "\n",
    "# pre-processing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "# modelling\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# modelling pipeline\n",
    "from tempfile import mkdtemp\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# modelling evaluation\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2422a3a6",
   "metadata": {},
   "source": [
    "Future pipeline:\n",
    "\n",
    "For each classifier -><br>\n",
    "Separate to X and Y<br>\n",
    "TF-IDF here option 1 <br>\n",
    "Step for SF'ing<br>\n",
    "TF-IDF here option 2 <br>\n",
    "Split into folds (5-fold CV)<br>\n",
    "3x3 SVM Hyperparameters<br>\n",
    "Find best neg F1 score\n",
    "\n",
    "Plus anything else"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0943e8a",
   "metadata": {},
   "source": [
    "Pipeline to make now:\n",
    "\n",
    "1. Separate into classifiers. For each classifier:\n",
    "2. Apply SF'd\n",
    "3. Separate into X and Y\n",
    "4. Crate TF-IDF Matrix\n",
    "4. Split each set into 5 folds\n",
    "5. Grid search over SVM Hyperparameters to optimise F1 score\n",
    "\n",
    "Output.\n",
    "\n",
    "This will be a moderate approximation for a replication of most of their work. Main missing element will be better text pre-processing to get better results from the CFs and SF'ing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc034a58",
   "metadata": {},
   "source": [
    "Do it for one classifier, then find how to generalise it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1d5d3a",
   "metadata": {},
   "source": [
    "Train, Validate and Test dataframes to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c1d24f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_pipelining = pd.read_pickle(\"crafted_features_df.pkl\")\n",
    "\n",
    "df_for_pipelining_train = df_for_pipelining.loc[df_for_pipelining['policy_type'] == 'TRAINING' ].copy()\n",
    "df_for_pipelining_val = df_for_pipelining.loc[df_for_pipelining['policy_type'] == 'VALIDATION' ].copy()\n",
    "df_for_pipelining_test = df_for_pipelining.loc[df_for_pipelining['policy_type'] == 'TEST' ].copy()\n",
    "\n",
    "# now that I have used the 'policy type' column for referring to train/validate/test, \n",
    "# I can delete that column along with other uneccesary columns.\n",
    "for dataframe in [df_for_pipelining_train, df_for_pipelining_val, df_for_pipelining_test]:\n",
    "    dataframe.drop(columns=['source_policy_number', 'policy_type', 'contains_synthetic',\n",
    "           'policy_segment_id', 'annotations', 'sentences'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "585fa819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8068, 614)\n",
      "(2651, 614)\n",
      "(4824, 614)\n"
     ]
    }
   ],
   "source": [
    "print(df_for_pipelining_train.shape)\n",
    "print(df_for_pipelining_val.shape)\n",
    "print(df_for_pipelining_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c2db48",
   "metadata": {},
   "source": [
    "# Step 1: select classifier\n",
    "\n",
    "Let's start with 1st Party."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "565514c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = \"1st_party\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bbb83b",
   "metadata": {},
   "source": [
    "# Step 2: apply SF'ing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc013b2d",
   "metadata": {},
   "source": [
    "1. Get CFs for 1st Party to use for SF'ing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d283eb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' we ', ' you ', ' us ', ' our ', 'the app', 'the software']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_features = pd.read_pickle(\"annotation_features.pkl\")\n",
    "\n",
    "# filtering the table to get the list object from the same row that lists the classifier\n",
    "classifier_features = annotation_features[ annotation_features['annotation'] == classifier ].reset_index().at[0,'features']\n",
    "\n",
    "classifier_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c6248b",
   "metadata": {},
   "source": [
    "2. Filter the DF for rows where any of those features is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4d56b730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8068, 614)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_pipelining_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7903b0f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5101, 614)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_pipelining_train_SF = df_for_pipelining_train[( (df_for_pipelining_train[classifier_features] > 0).sum(axis=1) > 0 )]\n",
    "df_for_pipelining_train_SF.reset_index(inplace=True, drop=True)\n",
    "df_for_pipelining_train_SF.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4e3f6d",
   "metadata": {},
   "source": [
    "# Step 3: Separate into X and Y\n",
    "\n",
    "## Create X\n",
    "X requires a union of the Crafted Features columns and the TF-IDF matrix.\n",
    "\n",
    "Create TF-IDF matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0aa24752",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfTransformer = TfidfVectorizer(ngram_range=(1,2), stop_words='english', binary=True)\n",
    "\n",
    "train_tfidf = tfidfTransformer.fit_transform(df_for_pipelining_train_SF['segment_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a23f3f",
   "metadata": {},
   "source": [
    "Extract CF columns from X_train and convert to sparse so that it can be combined with TF-IDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b2d43e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should be left with the 579 crafted features (CF). CF shape is: (5101, 579)\n"
     ]
    }
   ],
   "source": [
    "# Extract CF columns:\n",
    "classifier_X_train_cfs = df_for_pipelining_train_SF.loc[:,'contact info':].copy()\n",
    "# Use every column after and including the first crafted feature, which happens to be 'contact info'\n",
    "print(f\"Should be left with the 579 crafted features (CF). CF shape is: {classifier_X_train_cfs.shape}\")\n",
    "\n",
    "#convert to sparse\n",
    "classifier_X_train_cfs = csr_matrix(classifier_X_train_cfs)\n",
    "\n",
    "# combine CF columns with TF-IDF to create X\n",
    "classifier_X_train = hstack([classifier_X_train_cfs, train_tfidf ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1026263",
   "metadata": {},
   "source": [
    "## Create y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "709d38ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_y_train = df_for_pipelining_train_SF.loc[:,classifier].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed6cef88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest value should be one. Highest value is: 1\n"
     ]
    }
   ],
   "source": [
    "# Ensure Y_train only has binary values\n",
    "for i in range(len(classifier_y_train)):\n",
    "    if classifier_y_train[i] > 1:\n",
    "        classifier_y_train[i] = 1\n",
    "print(f\"Highest value should be one. Highest value is: {classifier_y_train.max()}\") # should be 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7927efab",
   "metadata": {},
   "source": [
    "# Step 4: 5-fold CV Grid Search over hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34da8b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "cachedir = mkdtemp() # Memory dump to help with processing\n",
    "\n",
    "pipeline_sequences = [\n",
    "        ('SVC', SVC()) ]\n",
    "pipe = Pipeline(pipeline_sequences, memory = cachedir)\n",
    "\n",
    "svc_params = {'SVC__C': [0.1, 1, 10],\n",
    "             'SVC__gamma': [0.001, 0.01, 0.1]}\n",
    "\n",
    "# Create grid search object\n",
    "grid_search_object = GridSearchCV(estimator=pipe, param_grid = svc_params, cv = 5, verbose=1, n_jobs=-1, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1f9b273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "CPU times: user 5.5 s, sys: 144 ms, total: 5.65 s\n",
      "Wall time: 50.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fitted_search = grid_search_object.fit(classifier_X_train, classifier_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92dc002",
   "metadata": {},
   "source": [
    "# Evaluation on Train set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab55e38",
   "metadata": {},
   "source": [
    "To compare to the per-classifier results given in the paper (Table 1 pg 4), I only need to look at F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bd8f77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3745\n",
      "           1       1.00      1.00      1.00      1356\n",
      "\n",
      "    accuracy                           1.00      5101\n",
      "   macro avg       1.00      1.00      1.00      5101\n",
      "weighted avg       1.00      1.00      1.00      5101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_prediction = fitted_search.predict(classifier_X_train)\n",
    "print(classification_report(classifier_y_train, classifier_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577d0f22",
   "metadata": {},
   "source": [
    "Okay, I need to do my CV grid search on just the Train set, then evaluate performance using the Validate set, since it's massively overfitting on the train set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541b0b32",
   "metadata": {},
   "source": [
    "# Evaluation on Validate set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a936e811",
   "metadata": {},
   "source": [
    "Pre-processing steps to prepare the validate set for prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7173c9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_pipelining_val = df_for_pipelining.loc[df_for_pipelining['policy_type'] == 'VALIDATION' ].copy()\n",
    "df_for_pipelining_val.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "787f50a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest value should be one. Highest value is: 1\n"
     ]
    }
   ],
   "source": [
    "val_tfidf = tfidfTransformer.transform(df_for_pipelining_val['segment_text'])\n",
    "# Extract CF columns:\n",
    "classifier_X_val_cfs = df_for_pipelining_val.loc[:,'contact info':].copy()\n",
    "#convert to sparse\n",
    "classifier_X_val_cfs = csr_matrix(classifier_X_val_cfs)\n",
    "\n",
    "# combine CF columns with TF-IDF to create X\n",
    "classifier_X_val = hstack([classifier_X_val_cfs, val_tfidf ])\n",
    "\n",
    "classifier_y_val = df_for_pipelining_val.loc[:,classifier].copy()\n",
    "# Ensure Y_val only has binary values\n",
    "for i in range(len(classifier_y_val)):\n",
    "    if classifier_y_val[i] > 1:\n",
    "        classifier_y_val[i] = 1\n",
    "print(f\"Highest value should be one. Highest value is: {classifier_y_val.max()}\") # should be 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772055a5",
   "metadata": {},
   "source": [
    "Scoring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d1c7fd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_val_prediction = fitted_search.predict(classifier_X_val)\n",
    "\n",
    "model_results[classifier] = [fitted_search, classifier_y_val, classifier_val_prediction]\n",
    "model_results.to_pickle(\"model_results.pkl\")\n",
    "\n",
    "# print(classification_report(classifier_y_val, classifier_val_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cf6285",
   "metadata": {},
   "source": [
    "Nice! Looks like this scored well.  Let's set up the pipeline for all the other classifiers and score them too. But I'm still not sure whether I want the positive F1 score or the negative F1 score.  I think that \"negative F-1 score\" is important because it relates to when a policy fails to mention an important practice.  We want to be sure that if a policy fails to mention it, the classifier correctly states that it is not mentioned.\n",
    "\n",
    "Okay so Negative Recall is the proportion of When it was not in, did it say that it was not in?<br>\n",
    "Negative Precision then is when it predicted that it wasn't in, how often was that the case?\n",
    "\n",
    "Positive recall is When it was in, what was the chance it was identified?  <br>Positive precision is When it was predicted to be in, what was the chance that it was in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d913c35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(classifier_y_val, classifier_val_prediction)\n",
    "cf_df = pd.DataFrame(\n",
    "    cf_matrix, columns=[\"Predicted Negative\", \"Predicted Positive\"], index=[\"True Negative\", \"True Positive\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dd8e0d",
   "metadata": {},
   "source": [
    "I think that I want to store negative precision, negative recall, negative F1 and positive F1.\n",
    "\n",
    "This seems like a lot of things to store for each classifier.\n",
    "\n",
    "I think I can just store the tuple of `(classifier_y_val, classifier_val_prediction)`\n",
    "\n",
    "Then from that I can extract and populate a bigger table if I want."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4226ef24",
   "metadata": {},
   "source": [
    "Could store as lists... for each model, have a list with 3 values: fitted search, classifier_y_val, classifier_val_prediction.  Then could store each of those lists in a series where the index is the classifier.\n",
    "\n",
    "Could store as dictionaries.  Each key is the classifier and each value is the list.\n",
    "\n",
    "Then could loop through to get matrix (table) of scores.\n",
    "\n",
    "In fact I think it will be helpful to have the order be the same as the order that I pass the classifiers, so I should use a series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7af119",
   "metadata": {},
   "source": [
    "### Requirements for modelling pipeline:\n",
    "\n",
    "- List of all classifiers\n",
    "- df_for_pipelining_train/val/test\n",
    "- Empty table of classifier results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3108c75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_pipelining = pd.read_pickle(\"crafted_features_df.pkl\")\n",
    "\n",
    "df_for_pipelining_train = df_for_pipelining.loc[df_for_pipelining['policy_type'] == 'TRAINING' ].copy()\n",
    "df_for_pipelining_val = df_for_pipelining.loc[df_for_pipelining['policy_type'] == 'VALIDATION' ].copy()\n",
    "df_for_pipelining_val.reset_index(inplace=True, drop=True)\n",
    "df_for_pipelining_test = df_for_pipelining.loc[df_for_pipelining['policy_type'] == 'TEST' ].copy()\n",
    "df_for_pipelining_test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# now that I have used the 'policy type' column for referring to train/validate/test, \n",
    "# I can delete that column along with other uneccesary columns.\n",
    "for dataframe in [df_for_pipelining_train, df_for_pipelining_val, df_for_pipelining_test]:\n",
    "    dataframe.drop(columns=['source_policy_number', 'policy_type', 'contains_synthetic',\n",
    "           'policy_segment_id', 'annotations', 'sentences'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd9c742",
   "metadata": {},
   "source": [
    "List of all classifiers can be taken from any of the previous dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1cd1fc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_18_classifiers = ['Contact', 'Contact_E_Mail_Address', 'Contact_Phone_Number', \n",
    "                       'Identifier_Cookie_or_similar_Tech', 'Identifier_Device_ID', 'Identifier_IMEI',\n",
    "                        'Identifier_MAC', 'Identifier_Mobile_Carrier',\n",
    "                        'Location', 'Location_Cell_Tower', 'Location_GPS', 'Location_WiFi',\n",
    "                        'SSO', 'Facebook_SSO',\n",
    "                        '1st_party', '3rd_party',\n",
    "                        'PERFORMED', 'NOT_PERFORMED'] # cross-checked from table on pg 4 of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5bf524f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_results = pd.Series(range(len(list_of_18_classifiers)),\n",
    "                          index=list_of_18_classifiers, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "fcb51422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_modelling_pipeline(classifier, inspect_flow=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Passing inspect_flow=True will print out the shape of dataframes moving through the flow \n",
    "    \"\"\"\n",
    "    \n",
    "    # step 1\n",
    "    print(f\"Running for classifier: {classifier}\")\n",
    "    start_code_time = time.time()\n",
    "    \n",
    "    # step 2:\n",
    "    annotation_features = pd.read_pickle(\"annotation_features.pkl\")\n",
    "    df_for_pipelining_train_SF = model_pipeline_step_2(classifier, annotation_features)\n",
    "    if inspect_flow == True: print(f\"df_for_pipelining_train_SF: {df_for_pipelining_train_SF.shape}\")\n",
    "    \n",
    "    # step 3:\n",
    "    \n",
    "    classifier_X_train, tfidfTransformer = model_pipeline_step_3_1(df_for_pipelining_train_SF)\n",
    "    \n",
    "    classifier_y_train = model_pipeline_step_3_2(df_for_pipelining_train_SF)\n",
    "    \n",
    "    if inspect_flow == True: \n",
    "        print(f\"classifier_X_train (made of CFs plus tf-idf matrix): {classifier_X_train.shape}\")\n",
    "        print(f\"classifier_y_train: {classifier_y_train.shape}\")\n",
    "    \n",
    "    # step 4:\n",
    "    \n",
    "    fitted_search = model_pipeline_step_4(classifier_X_train, classifier_y_train)\n",
    "    \n",
    "    # step 5:\n",
    "    \n",
    "    classifier_X_val, classifier_y_val = model_pipeline_step_5_1(df_for_pipelining_val, tfidfTransformer)\n",
    "    if inspect_flow == True: \n",
    "        print(f\"classifier_X_val: {classifier_X_val.shape}\")\n",
    "        print(f\"classifier_y_val: {classifier_y_val.shape}\")\n",
    "    \n",
    "    model_pipeline_step_5_2(classifier, fitted_search, classifier_X_val, classifier_y_val)\n",
    "    \n",
    "    if type(model_results[classifier]) == int:\n",
    "        print(\"Model results not saved.\")\n",
    "        raise NotSavedError(\"Check model results\")\n",
    "    \n",
    "    print(f\"The runtime for {classifier} was {round(time.time() - start_code_time, 5)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a6da5885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline_step_2(classifier, annotation_features):\n",
    "    \n",
    "    # step 2 â€“ Get CFs for classifier to use for SF'ing\n",
    "    \n",
    "    # filtering the table to get the list object from the same row that lists the classifier:\n",
    "    classifier_features = annotation_features[ annotation_features['annotation'] == classifier ].reset_index().at[0,'features']\n",
    "    \n",
    "    # Filter the DF for rows where any of those features is 1:\n",
    "    df_for_pipelining_train_SF = df_for_pipelining_train[( (df_for_pipelining_train[classifier_features] > 0).sum(axis=1) > 0 )]\n",
    "    df_for_pipelining_train_SF.reset_index(inplace=True, drop=True)\n",
    "    print(f\"Shape of {classifier} train df after sentence filtering is: {df_for_pipelining_train_SF.shape}\")\n",
    "    \n",
    "    return df_for_pipelining_train_SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d36c429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline_step_3_1(df_for_pipelining_train_SF):\n",
    "    # separate into X\n",
    "    \n",
    "    tfidfTransformer = TfidfVectorizer(ngram_range=(1,2), stop_words='english', binary=True)\n",
    "\n",
    "    train_tfidf = tfidfTransformer.fit_transform(df_for_pipelining_train_SF['segment_text'])\n",
    "    \n",
    "    # Extract CF columns:\n",
    "    classifier_X_train_cfs = df_for_pipelining_train_SF.loc[:,'contact info':].copy()\n",
    "    # Use every column after and including the first crafted feature, which happens to be 'contact info'\n",
    "    \n",
    "    if classifier_X_train_cfs.shape[1] != 579:\n",
    "        print(f\"Should be left with the 579 crafted features (CF). CF shape is: {classifier_X_train_cfs.shape}\")\n",
    "        raise Step_3_CF_error(\"Crafted features not being applied correctly\")\n",
    "\n",
    "    #convert to sparse\n",
    "    classifier_X_train_cfs = csr_matrix(classifier_X_train_cfs)\n",
    "\n",
    "    # combine CF columns with TF-IDF to create X\n",
    "    classifier_X_train = hstack([classifier_X_train_cfs, train_tfidf ])\n",
    "    return classifier_X_train, tfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "83018c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline_step_3_2(df_for_pipelining_train_SF):\n",
    "    # separate into y\n",
    "    \n",
    "    classifier_y_train = df_for_pipelining_train_SF.loc[:,classifier].copy()\n",
    "    # Ensure Y_train only has binary values\n",
    "    for i in range(len(classifier_y_train)):\n",
    "        if classifier_y_train[i] > 1:\n",
    "            classifier_y_train[i] = 1\n",
    "    \n",
    "    if classifier_y_train.max() != 1:\n",
    "        print(f\"Highest value should be one. Highest value is: {classifier_y_train.max()}\")\n",
    "        raise Step_3_y_error(\"train target colum not binary\")\n",
    "    \n",
    "    return classifier_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8d24f0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline_step_4(classifier_X_train, classifier_y_train):\n",
    "    cachedir = mkdtemp() # Memory dump to help with processing\n",
    "\n",
    "    pipeline_sequences = [\n",
    "            ('SVC', SVC()) ]\n",
    "    pipe = Pipeline(pipeline_sequences, memory = cachedir)\n",
    "\n",
    "    svc_params = {'SVC__C': [0.1, 1, 10],\n",
    "                 'SVC__gamma': [0.001, 0.01, 0.1]}\n",
    "\n",
    "    # Create grid search object\n",
    "    grid_search_object = GridSearchCV(estimator=pipe, param_grid = svc_params, cv = 5, verbose=0, n_jobs=-1, scoring='f1')\n",
    "    \n",
    "    fitted_search = grid_search_object.fit(classifier_X_train, classifier_y_train)\n",
    "    \n",
    "    return fitted_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3855ff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline_step_5_1(df_for_pipelining_val, tfidfTransformer):\n",
    "    # create validate X and y\n",
    "\n",
    "    val_tfidf = tfidfTransformer.transform(df_for_pipelining_val['segment_text'])\n",
    "    # Extract CF columns:\n",
    "    classifier_X_val_cfs = df_for_pipelining_val.loc[:,'contact info':].copy()\n",
    "    #convert to sparse\n",
    "    classifier_X_val_cfs = csr_matrix(classifier_X_val_cfs)\n",
    "\n",
    "    # combine CF columns with TF-IDF to create X\n",
    "    classifier_X_val = hstack([classifier_X_val_cfs, val_tfidf ])\n",
    "\n",
    "    classifier_y_val = df_for_pipelining_val.loc[:,classifier].copy()\n",
    "    # Ensure Y_val only has binary values\n",
    "    for i in range(len(classifier_y_val)):\n",
    "        if classifier_y_val[i] > 1:\n",
    "            classifier_y_val[i] = 1\n",
    "    \n",
    "    if classifier_y_val.max() != 1:\n",
    "        print(f\"Highest value should be one. Highest value is: {classifier_y_val.max()}\")\n",
    "        raise Step_5_val_error(\"Validation target column not binary\")\n",
    "    \n",
    "    return classifier_X_val, classifier_y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d2eb9855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline_step_5_2(classifier, fitted_search, classifier_X_val, classifier_y_val):\n",
    "    \n",
    "    # scoring\n",
    "    classifier_val_prediction = fitted_search.predict(classifier_X_val)\n",
    "\n",
    "    model_results[classifier] = [fitted_search, classifier_y_val, classifier_val_prediction]\n",
    "    \n",
    "    model_results.to_pickle(\"model_results.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4a553b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_classifiers = ['Identifier_Cookie_or_similar_Tech', 'Identifier_Device_ID', 'Identifier_IMEI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6273effd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for classifier: Identifier_Cookie_or_similar_Tech\n",
      "Shape of Identifier_Cookie_or_similar_Tech train df after sentence filtering is: (537, 614)\n",
      "df_for_pipelining_train_SF: (537, 614)\n",
      "classifier_X_train: (537, 16469)\n",
      "classifier_y_train: (537,)\n",
      "classifier_X_val: (2651, 16469)\n",
      "classifier_y_val: (2651,)\n",
      "The runtime for Identifier_Cookie_or_similar_Tech was 3.68092\n",
      "\n",
      "Running for classifier: Identifier_Device_ID\n",
      "Shape of Identifier_Device_ID train df after sentence filtering is: (151, 614)\n",
      "df_for_pipelining_train_SF: (151, 614)\n",
      "classifier_X_train: (151, 7172)\n",
      "classifier_y_train: (151,)\n",
      "classifier_X_val: (2651, 7172)\n",
      "classifier_y_val: (2651,)\n",
      "The runtime for Identifier_Device_ID was 0.53466\n",
      "\n",
      "Running for classifier: Identifier_IMEI\n",
      "Shape of Identifier_IMEI train df after sentence filtering is: (1, 614)\n",
      "df_for_pipelining_train_SF: (1, 614)\n",
      "classifier_X_train: (1, 701)\n",
      "classifier_y_train: (1,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot have number of splits n_splits=5 greater than the number of samples: n_samples=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [122]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m each_classifier \u001b[38;5;129;01min\u001b[39;00m three_classifiers:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mfull_modelling_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43meach_classifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minspect_flow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [114]\u001b[0m, in \u001b[0;36mfull_modelling_pipeline\u001b[0;34m(classifier, inspect_flow)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier_y_train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclassifier_y_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# step 4:\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m fitted_search \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_pipeline_step_4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassifier_X_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier_y_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# step 5:\u001b[39;00m\n\u001b[1;32m     32\u001b[0m classifier_X_val, classifier_y_val \u001b[38;5;241m=\u001b[39m model_pipeline_step_5_1(df_for_pipelining_val, tfidfTransformer)\n",
      "Input \u001b[0;32mIn [118]\u001b[0m, in \u001b[0;36mmodel_pipeline_step_4\u001b[0;34m(classifier_X_train, classifier_y_train)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Create grid search object\u001b[39;00m\n\u001b[1;32m     12\u001b[0m grid_search_object \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mpipe, param_grid \u001b[38;5;241m=\u001b[39m svc_params, cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m fitted_search \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassifier_X_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier_y_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fitted_search\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/priv_pol_nlp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/priv_pol_nlp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1379\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/priv_pol_nlp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:834\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[1;32m    822\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    824\u001b[0m         clone(base_estimator),\n\u001b[1;32m    825\u001b[0m         X,\n\u001b[1;32m    826\u001b[0m         y,\n\u001b[1;32m    827\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    828\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    829\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    830\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    831\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    832\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    833\u001b[0m     )\n\u001b[0;32m--> 834\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m \u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m )\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/priv_pol_nlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:333\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    331\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(X)\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m n_samples:\n\u001b[0;32m--> 333\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    334\u001b[0m         (\n\u001b[1;32m    335\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot have number of splits n_splits=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m greater\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    336\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m than the number of samples: n_samples=\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    337\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits, n_samples)\n\u001b[1;32m    338\u001b[0m     )\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msplit(X, y, groups):\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot have number of splits n_splits=5 greater than the number of samples: n_samples=1."
     ]
    }
   ],
   "source": [
    "for each_classifier in three_classifiers:\n",
    "    full_modelling_pipeline(each_classifier, inspect_flow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1e8b72cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Contact                                                                              0\n",
       "Contact_E_Mail_Address                                                               1\n",
       "Contact_Phone_Number                                                                 2\n",
       "Identifier_Cookie_or_similar_Tech    [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "Identifier_Device_ID                 [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "Identifier_IMEI                                                                      5\n",
       "Identifier_MAC                                                                       6\n",
       "Identifier_Mobile_Carrier                                                            7\n",
       "Location                                                                             8\n",
       "Location_Cell_Tower                                                                  9\n",
       "Location_GPS                                                                        10\n",
       "Location_WiFi                                                                       11\n",
       "SSO                                                                                 12\n",
       "Facebook_SSO                                                                        13\n",
       "1st_party                                                                           14\n",
       "3rd_party                                                                           15\n",
       "PERFORMED                                                                           16\n",
       "NOT_PERFORMED                                                                       17\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126bd9f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "priv_pol_nlp",
   "language": "python",
   "name": "priv_pol_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
