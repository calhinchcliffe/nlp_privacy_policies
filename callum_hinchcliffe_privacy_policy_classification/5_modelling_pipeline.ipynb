{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb32d037",
   "metadata": {},
   "source": [
    "In this notebook:\n",
    "\n",
    "Modelling pipeline: grid search over all classes.\n",
    "\n",
    "Then to make bigrams and sentence filtering optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "86a733d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "import sys\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "import ds_utils_callum\n",
    "import priv_policy_manipulation_functions as priv_pol_funcs\n",
    "\n",
    "# pre-processing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "# modelling\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# modelling pipeline\n",
    "from tempfile import mkdtemp\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# modelling evaluation\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2422a3a6",
   "metadata": {},
   "source": [
    "Future pipeline:\n",
    "\n",
    "For each classifier -><br>\n",
    "Separate to X and Y<br>\n",
    "TF-IDF here option 1 <br>\n",
    "Step for SF'ing<br>\n",
    "TF-IDF here option 2 <br>\n",
    "Split into folds (5-fold CV)<br>\n",
    "3x3 SVM Hyperparameters<br>\n",
    "Find best neg F1 score\n",
    "\n",
    "Plus anything else"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0943e8a",
   "metadata": {},
   "source": [
    "Pipeline to make now:\n",
    "\n",
    "1. Separate into classifiers. For each classifier:\n",
    "2. Apply SF'd\n",
    "3. Separate into X and Y\n",
    "4. Crate TF-IDF Matrix\n",
    "4. Split each set into 5 folds\n",
    "5. Grid search over SVM Hyperparameters to optimise F1 score\n",
    "\n",
    "Output.\n",
    "\n",
    "This will be a moderate approximation for a replication of most of their work. Main missing element will be better text pre-processing to get better results from the CFs and SF'ing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc034a58",
   "metadata": {},
   "source": [
    "Do it for one classifier, then find how to generalise it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1d5d3a",
   "metadata": {},
   "source": [
    "Train, Validate and Test dataframes to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c1d24f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_pipelining = pd.read_pickle(\"crafted_features_df.pkl\")\n",
    "\n",
    "df_for_pipelining_train = df_for_pipelining.loc[df_for_pipelining['policy_type'] == 'TRAINING' ].copy()\n",
    "df_for_pipelining_val = df_for_pipelining.loc[df_for_pipelining['policy_type'] == 'VALIDATION' ].copy()\n",
    "df_for_pipelining_test = df_for_pipelining.loc[df_for_pipelining['policy_type'] == 'TEST' ].copy()\n",
    "\n",
    "# now that I have used the 'policy type' column for referring to train/validate/test, \n",
    "# I can delete that column along with other uneccesary columns.\n",
    "for dataframe in [df_for_pipelining_train, df_for_pipelining_val, df_for_pipelining_test]:\n",
    "    dataframe.drop(columns=['source_policy_number', 'policy_type', 'contains_synthetic',\n",
    "           'policy_segment_id', 'annotations', 'sentences'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b34e9bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8068, 511)\n",
      "(2651, 511)\n",
      "(4824, 511)\n"
     ]
    }
   ],
   "source": [
    "print(df_for_pipelining_train.shape)\n",
    "print(df_for_pipelining_val.shape)\n",
    "print(df_for_pipelining_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "414ab815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotation features to use for sentence filtering\n",
    "clean_annotation_features = pd.read_pickle(\"clean_annotation_features.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c2db48",
   "metadata": {},
   "source": [
    "# Step 1: select classifier\n",
    "\n",
    "Let's start with 1st Party as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "565514c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = \"1st_party\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bbb83b",
   "metadata": {},
   "source": [
    "# Step 2: apply SF'ing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc013b2d",
   "metadata": {},
   "source": [
    "1. Get CFs for 1st Party to use for SF'ing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d283eb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['we', 'you', 'us', 'our', 'the app', 'the software']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtering the table to get the list object from the same row that lists the classifier\n",
    "classifier_features = clean_annotation_features[ clean_annotation_features['annotation'] == classifier ].reset_index().at[0,'features']\n",
    "\n",
    "classifier_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c6248b",
   "metadata": {},
   "source": [
    "2. Filter the DF for rows where any of those features is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1dce19d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8068, 511)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_pipelining_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7903b0f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7297, 511)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_pipelining_train_SF = df_for_pipelining_train[( (df_for_pipelining_train[classifier_features] > 0).sum(axis=1) > 0 )]\n",
    "df_for_pipelining_train_SF.reset_index(inplace=True, drop=True)\n",
    "df_for_pipelining_train_SF.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4e3f6d",
   "metadata": {},
   "source": [
    "# Step 3: Separate into X and Y\n",
    "\n",
    "## Create X\n",
    "X requires a union of the Crafted Features columns and the TF-IDF matrix.\n",
    "\n",
    "Create TF-IDF matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0aa24752",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfTransformer = TfidfVectorizer(ngram_range=(1,2), stop_words='english', binary=True)\n",
    "\n",
    "train_tfidf = tfidfTransformer.fit_transform(df_for_pipelining_train_SF['segment_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a23f3f",
   "metadata": {},
   "source": [
    "Extract CF columns from X_train and convert to sparse so that it can be combined with TF-IDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5b2d43e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should be left with the 476 different crafted features (CFs). CF shape is: (7297, 476)\n"
     ]
    }
   ],
   "source": [
    "# Extract CF columns:\n",
    "classifier_X_train_cfs = df_for_pipelining_train_SF.loc[:,'contact info':].copy()\n",
    "# Use every column after and including the first crafted feature, which happens to be 'contact info'\n",
    "print(f\"Should be left with the 476 different crafted features (CFs). CF shape is: {classifier_X_train_cfs.shape}\")\n",
    "\n",
    "#convert to sparse\n",
    "classifier_X_train_cfs = csr_matrix(classifier_X_train_cfs)\n",
    "\n",
    "# combine CF columns with TF-IDF to create X\n",
    "classifier_X_train = hstack([classifier_X_train_cfs, train_tfidf ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1026263",
   "metadata": {},
   "source": [
    "## Create y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "709d38ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_y_train = df_for_pipelining_train_SF.loc[:,classifier].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ed6cef88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest value should be one. Highest value is: 1\n"
     ]
    }
   ],
   "source": [
    "# Ensure Y_train only has binary values\n",
    "for i in range(len(classifier_y_train)):\n",
    "    if classifier_y_train[i] > 1:\n",
    "        classifier_y_train[i] = 1\n",
    "print(f\"Highest value should be one. Highest value is: {classifier_y_train.max()}\") # should be 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7927efab",
   "metadata": {},
   "source": [
    "# Step 4: 5-fold CV Grid Search over hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "34da8b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "cachedir = mkdtemp() # Memory dump to help with processing\n",
    "\n",
    "pipeline_sequences = [\n",
    "        ('SVC', SVC()) ]\n",
    "pipe = Pipeline(pipeline_sequences, memory = cachedir)\n",
    "\n",
    "svc_params = {'SVC__C': [0.1, 1, 10],\n",
    "             'SVC__gamma': [0.001, 0.01, 0.1]}\n",
    "\n",
    "# Create grid search object\n",
    "grid_search_object = GridSearchCV(estimator=pipe, param_grid = svc_params, cv = 5, verbose=1, n_jobs=-1, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f1f9b273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "CPU times: user 9.11 s, sys: 230 ms, total: 9.34 s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fitted_search = grid_search_object.fit(classifier_X_train, classifier_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92dc002",
   "metadata": {},
   "source": [
    "# Evaluation on Train set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab55e38",
   "metadata": {},
   "source": [
    "To compare to the per-classifier results given in the paper (Table 1 pg 4), I only need to look at F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2bd8f77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5504\n",
      "           1       1.00      1.00      1.00      1793\n",
      "\n",
      "    accuracy                           1.00      7297\n",
      "   macro avg       1.00      1.00      1.00      7297\n",
      "weighted avg       1.00      1.00      1.00      7297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_prediction = fitted_search.predict(classifier_X_train)\n",
    "print(classification_report(classifier_y_train, classifier_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577d0f22",
   "metadata": {},
   "source": [
    "Okay, I need to do my CV grid search on just the Train set, then evaluate performance using the Validate set, since it's massively overfitting on the train set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541b0b32",
   "metadata": {},
   "source": [
    "# Evaluation on Validate set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a936e811",
   "metadata": {},
   "source": [
    "Pre-processing steps to prepare the validate set for prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "aa31bd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_pipelining_val = df_for_pipelining.loc[df_for_pipelining['policy_type'] == 'VALIDATION' ].copy()\n",
    "df_for_pipelining_val.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "787f50a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest value should be one. Highest value is: 1\n"
     ]
    }
   ],
   "source": [
    "val_tfidf = tfidfTransformer.transform(df_for_pipelining_val['segment_text'])\n",
    "# Extract CF columns:\n",
    "classifier_X_val_cfs = df_for_pipelining_val.loc[:,'contact info':].copy()\n",
    "#convert to sparse\n",
    "classifier_X_val_cfs = csr_matrix(classifier_X_val_cfs)\n",
    "\n",
    "# combine CF columns with TF-IDF to create X\n",
    "classifier_X_val = hstack([classifier_X_val_cfs, val_tfidf ])\n",
    "\n",
    "classifier_y_val = df_for_pipelining_val.loc[:,classifier].copy()\n",
    "# Ensure Y_val only has binary values\n",
    "for i in range(len(classifier_y_val)):\n",
    "    if classifier_y_val[i] > 1:\n",
    "        classifier_y_val[i] = 1\n",
    "print(f\"Highest value should be one. Highest value is: {classifier_y_val.max()}\") # should be 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772055a5",
   "metadata": {},
   "source": [
    "Scoring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d1c7fd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_val_prediction = fitted_search.predict(classifier_X_val)\n",
    "\n",
    "model_results[classifier] = [fitted_search, classifier_y_val, classifier_val_prediction]\n",
    "model_results.to_pickle(\"model_results.pkl\")\n",
    "\n",
    "# print(classification_report(classifier_y_val, classifier_val_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cf6285",
   "metadata": {},
   "source": [
    "Nice! Looks like this scored well.  Let's set up the pipeline for all the other classifiers and score them too. But I'm still not sure whether I want the positive F1 score or the negative F1 score.  I think that \"negative F-1 score\" is important because it relates to when a policy fails to mention an important practice.  We want to be sure that if a policy fails to mention it, the classifier correctly states that it is not mentioned.\n",
    "\n",
    "Okay so Negative Recall is the proportion of When it was not in, did it say that it was not in?<br>\n",
    "Negative Precision then is when it predicted that it wasn't in, how often was that the case?\n",
    "\n",
    "Positive recall is When it was in, what was the chance it was identified?  <br>Positive precision is When it was predicted to be in, what was the chance that it was in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d913c35e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Negative</th>\n",
       "      <th>Predicted Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True Negative</th>\n",
       "      <td>1893</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Positive</th>\n",
       "      <td>107</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Predicted Negative  Predicted Positive\n",
       "True Negative                1893                  81\n",
       "True Positive                 107                 570"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_confusion_matrix(classifier_y_val, classifier_val_prediction):\n",
    "    cf_matrix = confusion_matrix(classifier_y_val, classifier_val_prediction)\n",
    "    cf_df = pd.DataFrame(\n",
    "        cf_matrix, columns=[\"Predicted Negative\", \"Predicted Positive\"], index=[\"True Negative\", \"True Positive\"])\n",
    "    display(cf_df)\n",
    "show_confusion_matrix(classifier_y_val, classifier_val_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dd8e0d",
   "metadata": {},
   "source": [
    "I think that I want to store negative precision, negative recall, negative F1 and positive F1.\n",
    "\n",
    "This seems like a lot of things to store for each classifier.\n",
    "\n",
    "I think I can just store the tuple of `(classifier_y_val, classifier_val_prediction)`\n",
    "\n",
    "Then from that I can extract and populate a bigger table if I want."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4226ef24",
   "metadata": {},
   "source": [
    "Could store as lists... for each model, have a list with 3 values: fitted search, classifier_y_val, classifier_val_prediction.  Then could store each of those lists in a series where the index is the classifier.\n",
    "\n",
    "Could store as dictionaries.  Each key is the classifier and each value is the list.\n",
    "\n",
    "Then could loop through to get matrix (table) of scores.\n",
    "\n",
    "In fact I think it will be helpful to have the order be the same as the order that I pass the classifiers, so I should use a series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1770a1",
   "metadata": {},
   "source": [
    "### Requirements for modelling pipeline:\n",
    "\n",
    "- List of all classifiers\n",
    "- df_for_pipelining_train/val/test\n",
    "- Empty table of classifier results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "77316778",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_pipelining = pd.read_pickle(\"crafted_features_df.pkl\")\n",
    "\n",
    "df_for_pipelining_train = df_for_pipelining.loc[df_for_pipelining['policy_type'] == 'TRAINING' ].copy()\n",
    "df_for_pipelining_val = df_for_pipelining.loc[df_for_pipelining['policy_type'] == 'VALIDATION' ].copy()\n",
    "df_for_pipelining_val.reset_index(inplace=True, drop=True)\n",
    "df_for_pipelining_test = df_for_pipelining.loc[df_for_pipelining['policy_type'] == 'TEST' ].copy()\n",
    "df_for_pipelining_test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# now that I have used the 'policy type' column for referring to train/validate/test, \n",
    "# I can delete that column along with other uneccesary columns.\n",
    "for dataframe in [df_for_pipelining_train, df_for_pipelining_val, df_for_pipelining_test]:\n",
    "    dataframe.drop(columns=['source_policy_number', 'policy_type', 'contains_synthetic',\n",
    "           'policy_segment_id', 'annotations', 'sentences'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd9c742",
   "metadata": {},
   "source": [
    "List of all classifiers can be taken from any of the previous dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "1cd1fc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_18_classifiers = ['Contact', 'Contact_E_Mail_Address', 'Contact_Phone_Number', \n",
    "                       'Identifier_Cookie_or_similar_Tech', 'Identifier_Device_ID', 'Identifier_IMEI',\n",
    "                        'Identifier_MAC', 'Identifier_Mobile_Carrier',\n",
    "                        'Location', 'Location_Cell_Tower', 'Location_GPS', 'Location_WiFi',\n",
    "                        'SSO', 'Facebook_SSO',\n",
    "                        '1st_party', '3rd_party',\n",
    "                        'PERFORMED', 'NOT_PERFORMED'] # cross-checked from table on pg 4 of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5bf524f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_results = pd.Series(range(len(list_of_18_classifiers)),\n",
    "                          index=list_of_18_classifiers, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "fcb51422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_modelling_pipeline(classifier, model_results_series, sentence_filtering=True, inspect_flow=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        sentence_filtering: sentence_filtering takes a boolean, default True. If False, the flow will ommit the sentence filtering step.\n",
    "        \n",
    "        model_results_series: the empty series to which to save the results to. A pickle file of the same name will be saved with the results. \n",
    "        \n",
    "        inspect_flow: Passing inspect_flow=True will print out the shape of dataframes moving through the flow \n",
    "    \"\"\"\n",
    "    \n",
    "    # step 1\n",
    "    print(f\"Running for classifier: {classifier}\")\n",
    "    start_code_time = time.time()\n",
    "    \n",
    "    # step 2:\n",
    "    clean_annotation_features = pd.read_pickle(\"clean_annotation_features.pkl\")\n",
    "    \n",
    "    if sentence_filtering == True:\n",
    "        df_for_pipelining_train_SF = model_pipeline_step_2(classifier, clean_annotation_features)\n",
    "    elif sentence_filtering == False:\n",
    "        df_for_pipelining_train_SF = df_for_pipelining_train.copy()\n",
    "        df_for_pipelining_train_SF.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    if inspect_flow == True: print(f\"df_for_pipelining_train_SF: {df_for_pipelining_train_SF.shape}\")\n",
    "    \n",
    "    # step 3:\n",
    "    \n",
    "    classifier_X_train, tfidfTransformer = model_pipeline_step_3_1(df_for_pipelining_train_SF)\n",
    "    \n",
    "    classifier_y_train = model_pipeline_step_3_2(df_for_pipelining_train_SF)\n",
    "    \n",
    "    if inspect_flow == True: \n",
    "        print(f\"classifier_X_train (made of CFs plus tf-idf matrix): {classifier_X_train.shape}\")\n",
    "        print(f\"classifier_y_train: {classifier_y_train.shape}\")\n",
    "    \n",
    "    # step 4:\n",
    "    \n",
    "    fitted_search = model_pipeline_step_4(classifier_X_train, classifier_y_train)\n",
    "    \n",
    "    # step 5:\n",
    "    \n",
    "    classifier_X_val, classifier_y_val = model_pipeline_step_5_1(df_for_pipelining_val, tfidfTransformer)\n",
    "    if inspect_flow == True: \n",
    "        print(f\"classifier_X_val: {classifier_X_val.shape}\")\n",
    "        print(f\"classifier_y_val: {classifier_y_val.shape}\")\n",
    "    \n",
    "    model_pipeline_step_5_2(classifier, fitted_search, classifier_X_val, classifier_y_val, model_results_series)\n",
    "    \n",
    "    if type(model_results_series[classifier]) == int:\n",
    "        print(\"Model results not saved.\")\n",
    "        raise NotSavedError(\"Check model results\")\n",
    "    \n",
    "    print(f\"The runtime for {classifier} was {round(time.time() - start_code_time, 5)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a6da5885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline_step_2(classifier, clean_annotation_features):\n",
    "    \n",
    "    # step 2 – Get CFs for classifier to use for SF'ing\n",
    "    \n",
    "    # filtering the annotations & features table to get the list object from the same row that lists the classifier:\n",
    "    classifier_features = clean_annotation_features[ clean_annotation_features['annotation'] == classifier ].reset_index().at[0,'features']\n",
    "    \n",
    "    # Filter the DF for rows where any of those features is 1:\n",
    "    df_for_pipelining_train_SF = df_for_pipelining_train[( (df_for_pipelining_train[classifier_features] > 0).sum(axis=1) > 0 )]\n",
    "    df_for_pipelining_train_SF.reset_index(inplace=True, drop=True)\n",
    "    print(f\"Shape of {classifier} train df after sentence filtering is: {df_for_pipelining_train_SF.shape}\")\n",
    "    \n",
    "    return df_for_pipelining_train_SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d36c429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline_step_3_1(df_for_pipelining_train_SF):\n",
    "    # separate into X\n",
    "    \n",
    "    tfidfTransformer = TfidfVectorizer(ngram_range=(1,2), stop_words='english', binary=True)\n",
    "\n",
    "    train_tfidf = tfidfTransformer.fit_transform(df_for_pipelining_train_SF['segment_text'])\n",
    "    \n",
    "    # Extract CF columns:\n",
    "    classifier_X_train_cfs = df_for_pipelining_train_SF.loc[:,'contact info':].copy()\n",
    "    # Use every column after and including the first crafted feature, which happens to be 'contact info'\n",
    "    \n",
    "    if classifier_X_train_cfs.shape[1] != 476:\n",
    "        print(f\"Should be left with the 476 crafted features (CF). CF shape is: {classifier_X_train_cfs.shape}\")\n",
    "        raise Step_3_CF_error(\"Crafted features not being applied correctly\")\n",
    "\n",
    "    #convert to sparse\n",
    "    classifier_X_train_cfs = csr_matrix(classifier_X_train_cfs)\n",
    "\n",
    "    # combine CF columns with TF-IDF to create X\n",
    "    classifier_X_train = hstack([classifier_X_train_cfs, train_tfidf ])\n",
    "    return classifier_X_train, tfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "83018c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline_step_3_2(df_for_pipelining_train_SF):\n",
    "    # separate into y\n",
    "    \n",
    "    classifier_y_train = df_for_pipelining_train_SF.loc[:,classifier].copy()\n",
    "    # Ensure Y_train only has binary values\n",
    "    for i in range(len(classifier_y_train)):\n",
    "        if classifier_y_train[i] > 1:\n",
    "            classifier_y_train[i] = 1\n",
    "    \n",
    "    if classifier_y_train.max() != 1:\n",
    "        print(f\"Highest value should be one. Highest value is: {classifier_y_train.max()}\")\n",
    "        raise Step_3_y_error(\"train target colum not binary\")\n",
    "    \n",
    "    return classifier_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "a200e759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline_step_4(classifier_X_train, classifier_y_train):\n",
    "    cachedir = mkdtemp() # Memory dump to help with processing\n",
    "\n",
    "    pipeline_sequences = [\n",
    "            ('SVC', SVC()) ]\n",
    "    pipe = Pipeline(pipeline_sequences, memory = cachedir)\n",
    "\n",
    "    svc_params = {'SVC__C': [0.1, 1, 10],\n",
    "                 'SVC__gamma': [0.001, 0.01, 0.1]}\n",
    "\n",
    "    # Create grid search object\n",
    "    grid_search_object = GridSearchCV(estimator=pipe, param_grid = svc_params, cv = 5, verbose=0, n_jobs=-1, scoring='f1')\n",
    "    \n",
    "    fitted_search = grid_search_object.fit(classifier_X_train, classifier_y_train)\n",
    "    \n",
    "    return fitted_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "3b2b8e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline_step_5_1(df_for_pipelining_val, tfidfTransformer):\n",
    "    # create validate X and y\n",
    "\n",
    "    val_tfidf = tfidfTransformer.transform(df_for_pipelining_val['segment_text'])\n",
    "    # Extract CF columns:\n",
    "    classifier_X_val_cfs = df_for_pipelining_val.loc[:,'contact info':].copy()\n",
    "    #convert to sparse\n",
    "    classifier_X_val_cfs = csr_matrix(classifier_X_val_cfs)\n",
    "\n",
    "    # combine CF columns with TF-IDF to create X\n",
    "    classifier_X_val = hstack([classifier_X_val_cfs, val_tfidf ])\n",
    "\n",
    "    classifier_y_val = df_for_pipelining_val.loc[:,classifier].copy()\n",
    "    # Ensure Y_val only has binary values\n",
    "    for i in range(len(classifier_y_val)):\n",
    "        if classifier_y_val[i] > 1:\n",
    "            classifier_y_val[i] = 1\n",
    "    \n",
    "    if classifier_y_val.max() != 1:\n",
    "        print(f\"Highest value should be one. Highest value is: {classifier_y_val.max()}\")\n",
    "        raise Step_5_val_error(\"Validation target column not binary\")\n",
    "    \n",
    "    return classifier_X_val, classifier_y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b187f2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline_step_5_2(classifier, fitted_search, classifier_X_val, classifier_y_val, model_results_series):\n",
    "    \n",
    "    # scoring\n",
    "    classifier_val_prediction = fitted_search.predict(classifier_X_val)\n",
    "\n",
    "    model_results_series[classifier] = [fitted_search, classifier_y_val, classifier_val_prediction]\n",
    "    \n",
    "    model_results_series.to_pickle(f\"most_recent_model_results.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4388b0",
   "metadata": {},
   "source": [
    "# Run all classifiers through the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad76d63",
   "metadata": {},
   "source": [
    "My initial results will be with sentence filtering included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c0ba8d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_results_sf = pd.Series(range(len(list_of_18_classifiers)),\n",
    "                          index=list_of_18_classifiers, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f4e25149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for classifier: Contact\n",
      "Shape of Contact train df after sentence filtering is: (366, 511)\n",
      "df_for_pipelining_train_SF: (366, 511)\n",
      "classifier_X_train (made of CFs plus tf-idf matrix): (366, 13708)\n",
      "classifier_y_train: (366,)\n",
      "classifier_X_val: (2651, 13708)\n",
      "classifier_y_val: (2651,)\n",
      "The runtime for Contact was 0.9684\n",
      "\n",
      "Running for classifier: Contact_E_Mail_Address\n",
      "Shape of Contact_E_Mail_Address train df after sentence filtering is: (557, 511)\n",
      "df_for_pipelining_train_SF: (557, 511)\n",
      "classifier_X_train (made of CFs plus tf-idf matrix): (557, 16513)\n",
      "classifier_y_train: (557,)\n",
      "classifier_X_val: (2651, 16513)\n",
      "classifier_y_val: (2651,)\n",
      "The runtime for Contact_E_Mail_Address was 1.23097\n",
      "\n",
      "Running for classifier: Contact_Phone_Number\n",
      "Shape of Contact_Phone_Number train df after sentence filtering is: (487, 511)\n",
      "df_for_pipelining_train_SF: (487, 511)\n",
      "classifier_X_train (made of CFs plus tf-idf matrix): (487, 16970)\n",
      "classifier_y_train: (487,)\n",
      "classifier_X_val: (2651, 16970)\n",
      "classifier_y_val: (2651,)\n",
      "The runtime for Contact_Phone_Number was 1.32518\n",
      "\n",
      "Running for classifier: Identifier_Cookie_or_similar_Tech\n",
      "Shape of Identifier_Cookie_or_similar_Tech train df after sentence filtering is: (679, 511)\n",
      "df_for_pipelining_train_SF: (679, 511)\n",
      "classifier_X_train (made of CFs plus tf-idf matrix): (679, 18904)\n",
      "classifier_y_train: (679,)\n",
      "classifier_X_val: (2651, 18904)\n",
      "classifier_y_val: (2651,)\n",
      "The runtime for Identifier_Cookie_or_similar_Tech was 2.19547\n",
      "\n",
      "Running for classifier: Identifier_Device_ID\n",
      "Shape of Identifier_Device_ID train df after sentence filtering is: (271, 511)\n",
      "df_for_pipelining_train_SF: (271, 511)\n",
      "classifier_X_train (made of CFs plus tf-idf matrix): (271, 9529)\n",
      "classifier_y_train: (271,)\n",
      "classifier_X_val: (2651, 9529)\n",
      "classifier_y_val: (2651,)\n",
      "The runtime for Identifier_Device_ID was 0.77401\n",
      "\n",
      "Running for classifier: Identifier_IMEI\n",
      "Shape of Identifier_IMEI train df after sentence filtering is: (43, 511)\n",
      "df_for_pipelining_train_SF: (43, 511)\n",
      "classifier_X_train (made of CFs plus tf-idf matrix): (43, 1872)\n",
      "classifier_y_train: (43,)\n",
      "classifier_X_val: (2651, 1872)\n",
      "classifier_y_val: (2651,)\n",
      "The runtime for Identifier_IMEI was 0.30025\n",
      "\n",
      "Running for classifier: Identifier_MAC\n",
      "Shape of Identifier_MAC train df after sentence filtering is: (140, 511)\n",
      "df_for_pipelining_train_SF: (140, 511)\n",
      "classifier_X_train (made of CFs plus tf-idf matrix): (140, 7996)\n",
      "classifier_y_train: (140,)\n",
      "classifier_X_val: (2651, 7996)\n",
      "classifier_y_val: (2651,)\n",
      "The runtime for Identifier_MAC was 0.51553\n",
      "\n",
      "Running for classifier: Identifier_Mobile_Carrier\n",
      "Shape of Identifier_Mobile_Carrier train df after sentence filtering is: (69, 511)\n",
      "df_for_pipelining_train_SF: (69, 511)\n",
      "classifier_X_train (made of CFs plus tf-idf matrix): (69, 4623)\n",
      "classifier_y_train: (69,)\n",
      "classifier_X_val: (2651, 4623)\n",
      "classifier_y_val: (2651,)\n",
      "The runtime for Identifier_Mobile_Carrier was 0.34136\n",
      "\n",
      "Running for classifier: Location\n",
      "Shape of Location train df after sentence filtering is: (678, 511)\n",
      "df_for_pipelining_train_SF: (678, 511)\n",
      "classifier_X_train (made of CFs plus tf-idf matrix): (678, 20937)\n",
      "classifier_y_train: (678,)\n",
      "classifier_X_val: (2651, 20937)\n",
      "classifier_y_val: (2651,)\n",
      "The runtime for Location was 2.37372\n",
      "\n",
      "Running for classifier: Location_Cell_Tower\n",
      "Shape of Location_Cell_Tower train df after sentence filtering is: (74, 511)\n",
      "df_for_pipelining_train_SF: (74, 511)\n",
      "classifier_X_train (made of CFs plus tf-idf matrix): (74, 3509)\n",
      "classifier_y_train: (74,)\n",
      "classifier_X_val: (2651, 3509)\n",
      "classifier_y_val: (2651,)\n",
      "The runtime for Location_Cell_Tower was 0.33246\n",
      "\n",
      "Running for classifier: Location_GPS\n",
      "Shape of Location_GPS train df after sentence filtering is: (133, 511)\n",
      "df_for_pipelining_train_SF: (133, 511)\n",
      "classifier_X_train (made of CFs plus tf-idf matrix): (133, 6103)\n",
      "classifier_y_train: (133,)\n",
      "classifier_X_val: (2651, 6103)\n",
      "classifier_y_val: (2651,)\n",
      "The runtime for Location_GPS was 0.45809\n",
      "\n",
      "Running for classifier: Location_WiFi\n",
      "Shape of Location_WiFi train df after sentence filtering is: (101, 511)\n",
      "df_for_pipelining_train_SF: (101, 511)\n",
      "classifier_X_train (made of CFs plus tf-idf matrix): (101, 5253)\n",
      "classifier_y_train: (101,)\n",
      "classifier_X_val: (2651, 5253)\n",
      "classifier_y_val: (2651,)\n",
      "The runtime for Location_WiFi was 0.41578\n",
      "\n",
      "Running for classifier: SSO\n",
      "Shape of SSO train df after sentence filtering is: (23, 511)\n",
      "df_for_pipelining_train_SF: (23, 511)\n",
      "classifier_X_train (made of CFs plus tf-idf matrix): (23, 1480)\n",
      "classifier_y_train: (23,)\n",
      "classifier_X_val: (2651, 1480)\n",
      "classifier_y_val: (2651,)\n",
      "The runtime for SSO was 0.26953\n",
      "\n",
      "Running for classifier: Facebook_SSO\n",
      "Shape of Facebook_SSO train df after sentence filtering is: (23, 511)\n",
      "df_for_pipelining_train_SF: (23, 511)\n",
      "classifier_X_train (made of CFs plus tf-idf matrix): (23, 1480)\n",
      "classifier_y_train: (23,)\n",
      "classifier_X_val: (2651, 1480)\n",
      "classifier_y_val: (2651,)\n",
      "The runtime for Facebook_SSO was 0.25409\n",
      "\n",
      "Running for classifier: 1st_party\n",
      "Shape of 1st_party train df after sentence filtering is: (7297, 511)\n",
      "df_for_pipelining_train_SF: (7297, 511)\n",
      "classifier_X_train (made of CFs plus tf-idf matrix): (7297, 108769)\n",
      "classifier_y_train: (7297,)\n",
      "classifier_X_val: (2651, 108769)\n",
      "classifier_y_val: (2651,)\n",
      "The runtime for 1st_party was 76.95603\n",
      "\n",
      "Running for classifier: 3rd_party\n",
      "Shape of 3rd_party train df after sentence filtering is: (4163, 511)\n",
      "df_for_pipelining_train_SF: (4163, 511)\n",
      "classifier_X_train (made of CFs plus tf-idf matrix): (4163, 76734)\n",
      "classifier_y_train: (4163,)\n",
      "classifier_X_val: (2651, 76734)\n",
      "classifier_y_val: (2651,)\n",
      "The runtime for 3rd_party was 37.04544\n",
      "\n",
      "Running for classifier: PERFORMED\n",
      "Shape of PERFORMED train df after sentence filtering is: (6742, 511)\n",
      "df_for_pipelining_train_SF: (6742, 511)\n",
      "classifier_X_train (made of CFs plus tf-idf matrix): (6742, 103405)\n",
      "classifier_y_train: (6742,)\n",
      "classifier_X_val: (2651, 103405)\n",
      "classifier_y_val: (2651,)\n",
      "The runtime for PERFORMED was 72.74551\n",
      "\n",
      "Running for classifier: NOT_PERFORMED\n",
      "Shape of NOT_PERFORMED train df after sentence filtering is: (3413, 511)\n",
      "df_for_pipelining_train_SF: (3413, 511)\n",
      "classifier_X_train (made of CFs plus tf-idf matrix): (3413, 70104)\n",
      "classifier_y_train: (3413,)\n",
      "classifier_X_val: (2651, 70104)\n",
      "classifier_y_val: (2651,)\n",
      "The runtime for NOT_PERFORMED was 26.41886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for each_classifier in list_of_18_classifiers:\n",
    "    full_modelling_pipeline(each_classifier, model_results_series=initial_results_sf, \n",
    "                            sentence_filtering=True, inspect_flow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2c40cab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Contact                   [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "Contact_E_Mail_Address    [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "dtype: object"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_results_sf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d712ef04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.07      0.12      1974\n",
      "           1       0.26      0.97      0.41       677\n",
      "\n",
      "    accuracy                           0.30      2651\n",
      "   macro avg       0.57      0.52      0.27      2651\n",
      "weighted avg       0.72      0.30      0.20      2651\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(initial_results_sf['Contact_E_Mail_Address'][1] , initial_results_sf['Contact_E_Mail_Address'][2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd79937",
   "metadata": {},
   "source": [
    "# Creating model evaluation table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e9818721",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_model_results = pd.read_pickle(\"most_recent_model_results.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b479ef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the classifiers as the index for our model results df\n",
    "initial_f1s = pd.DataFrame(initial_model_results, columns=[\"Neg F1\"]).copy()\n",
    "\n",
    "# then populate the dataframe with F1 scores by reference to the 'initial_model_results' series.\n",
    "# the initial_model_results series stores the actual and predicted y-values in the form [model_object, true_y, predicted_y]\n",
    "for index in initial_f1s.index:\n",
    "    initial_f1s.loc[index, \"Neg F1\"] = f1_score(initial_model_results[index][1].copy(), initial_model_results[index][2].copy(), pos_label=0)\n",
    "    initial_f1s.loc[index, \"Pos F1\"] = f1_score(initial_model_results[index][1].copy(), initial_model_results[index][2].copy(), pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6e4e3d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neg F1</th>\n",
       "      <th>Pos F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Contact</th>\n",
       "      <td>0.89243</td>\n",
       "      <td>0.664075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contact_E_Mail_Address</th>\n",
       "      <td>0.121641</td>\n",
       "      <td>0.414335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contact_Phone_Number</th>\n",
       "      <td>0.778331</td>\n",
       "      <td>0.598834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identifier_Cookie_or_similar_Tech</th>\n",
       "      <td>0.635948</td>\n",
       "      <td>0.503122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identifier_Device_ID</th>\n",
       "      <td>0.323308</td>\n",
       "      <td>0.442916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identifier_IMEI</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.406851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identifier_MAC</th>\n",
       "      <td>0.899355</td>\n",
       "      <td>0.623771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identifier_Mobile_Carrier</th>\n",
       "      <td>0.456351</td>\n",
       "      <td>0.448918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>0.521452</td>\n",
       "      <td>0.493204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location_Cell_Tower</th>\n",
       "      <td>0.056835</td>\n",
       "      <td>0.409690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location_GPS</th>\n",
       "      <td>0.493027</td>\n",
       "      <td>0.492261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location_WiFi</th>\n",
       "      <td>0.001013</td>\n",
       "      <td>0.406973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSO</th>\n",
       "      <td>0.853622</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Facebook_SSO</th>\n",
       "      <td>0.853622</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st_party</th>\n",
       "      <td>0.952693</td>\n",
       "      <td>0.858434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3rd_party</th>\n",
       "      <td>0.948795</td>\n",
       "      <td>0.845220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERFORMED</th>\n",
       "      <td>0.953436</td>\n",
       "      <td>0.860798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOT_PERFORMED</th>\n",
       "      <td>0.945628</td>\n",
       "      <td>0.834477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Neg F1    Pos F1\n",
       "Contact                             0.89243  0.664075\n",
       "Contact_E_Mail_Address             0.121641  0.414335\n",
       "Contact_Phone_Number               0.778331  0.598834\n",
       "Identifier_Cookie_or_similar_Tech  0.635948  0.503122\n",
       "Identifier_Device_ID               0.323308  0.442916\n",
       "Identifier_IMEI                         0.0  0.406851\n",
       "Identifier_MAC                     0.899355  0.623771\n",
       "Identifier_Mobile_Carrier          0.456351  0.448918\n",
       "Location                           0.521452  0.493204\n",
       "Location_Cell_Tower                0.056835  0.409690\n",
       "Location_GPS                       0.493027  0.492261\n",
       "Location_WiFi                      0.001013  0.406973\n",
       "SSO                                0.853622  0.000000\n",
       "Facebook_SSO                       0.853622  0.000000\n",
       "1st_party                          0.952693  0.858434\n",
       "3rd_party                          0.948795  0.845220\n",
       "PERFORMED                          0.953436  0.860798\n",
       "NOT_PERFORMED                      0.945628  0.834477"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_f1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "10084084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative F1 mean: 0.5937491023789958\n",
      "Positive F1 mean: 0.5168821926220422\n"
     ]
    }
   ],
   "source": [
    "print(f\"Negative F1 mean: {initial_f1s['Neg F1'].mean()}\")\n",
    "print(f\"Positive F1 mean: {initial_f1s['Pos F1'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4ebc42",
   "metadata": {},
   "source": [
    "Many things to discuss based on the above:\n",
    "- three 0 scores\n",
    "- wide range of scores\n",
    "- Neg F1 tends to be higher than Pos F1\n",
    "- compare with results from the paper\n",
    "\n",
    "\n",
    "# Discussion of Zero F1 scores\n",
    "There is one 0 for negative F1 `Identifier_IMEI` and two zero positive F1 scores for the two SSO classifiers.  Let's start by investigating `Identifier_IMEI`. \n",
    "\n",
    "## Zero score for IMEI Identifier\n",
    "\n",
    "A segment is annotated with 'Identifier_IMEI' if the segment describes how the company uses IMEI data to identify a customer. IMEI (International Mobile Equipment Identity) is a unique identification number all phone devices have, and can be used to track the history of the handset (including checking whether the phone has ever been reported as stolen).  First let's look at the confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6cb8ea58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Negative</th>\n",
       "      <th>Predicted Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True Negative</th>\n",
       "      <td>0</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Positive</th>\n",
       "      <td>0</td>\n",
       "      <td>677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Predicted Negative  Predicted Positive\n",
       "True Negative                   0                1974\n",
       "True Positive                   0                 677"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_confusion_matrix(initial_model_results['Identifier_IMEI'][1].copy(), initial_model_results['Identifier_IMEI'][2].copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5306af2e",
   "metadata": {},
   "source": [
    "The classifier never predicted that this label is not present.  This is likely because in the subset of the data that the classifier was trained on, all of the observations were positive cases. This will be the result of the sentence filtering – the classifier was only trained using text segments that mentioned phrases related to IMEI, all of which happened to be annotated as indicating that the practice was performed or not performed.\n",
    "\n",
    "This could mean that a rule-based classifier would be suitable for classifying the IMEI practice.  For a model-based classifier, I would need to use a wider range of features for sentence filtering, or would not conduct sentence filtering.\n",
    "\n",
    "We can see the features used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e434a6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['imei', 'international mobile equipment', 'equipment id'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_annotation_features[clean_annotation_features['annotation']=='Identifier_IMEI']['features'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d021f753",
   "metadata": {},
   "source": [
    "As expected there are very few related phrases.\n",
    "\n",
    "Another implication could be that because IMEI is so specific, companies will not mention anything related to it in their privacy policies unless they collect this data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244616ed",
   "metadata": {},
   "source": [
    "## Zero score for SSO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea5f051",
   "metadata": {},
   "source": [
    "The SSO (\"Single Sign On\") annotation is applied to a segment if it discusses what the company does with the data used to facilitate a single sign on service, such as when you sign into an app through your google or facebook account.  This is always passed to the appropriate third party to enact the service. The scores for both \"SSO\" and \"Facebook SSO\" are the same because the crafted features and most of the annotations are the same.  Again let's start by looking at the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "df2456bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Negative</th>\n",
       "      <th>Predicted Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True Negative</th>\n",
       "      <td>1974</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Positive</th>\n",
       "      <td>677</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Predicted Negative  Predicted Positive\n",
       "True Negative                1974                   0\n",
       "True Positive                 677                   0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_confusion_matrix(initial_model_results['SSO'][1].copy(), initial_model_results['SSO'][2].copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d016e6",
   "metadata": {},
   "source": [
    "This time the model never predicted that a segment contained a practice relating to SSO, but also the positive and negative proportions in the data match those for Identifier_IMEI.  It's unlikely that this occurred organically in the data so there must be a problem with the way the data has been processed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc62d5c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71560e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432792d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "184a899b",
   "metadata": {},
   "source": [
    "# Modelling without sentence filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "774dd3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_results_no_sf = pd.Series(range(len(list_of_18_classifiers)),\n",
    "                          index=list_of_18_classifiers, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7a2efbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for classifier: Contact_E_Mail_Address\n",
      "df_for_pipelining_train_SF: (8068, 511)\n",
      "classifier_X_train (made of CFs plus tf-idf matrix): (8068, 113262)\n",
      "classifier_y_train: (8068,)\n",
      "classifier_X_val: (2651, 113262)\n",
      "classifier_y_val: (2651,)\n",
      "The runtime for Contact_E_Mail_Address was 80.01306\n",
      "\n",
      "Running for classifier: Contact_Phone_Number\n",
      "df_for_pipelining_train_SF: (8068, 511)\n",
      "classifier_X_train (made of CFs plus tf-idf matrix): (8068, 113262)\n",
      "classifier_y_train: (8068,)\n",
      "classifier_X_val: (2651, 113262)\n",
      "classifier_y_val: (2651,)\n",
      "The runtime for Contact_Phone_Number was 76.93241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for each_classifier in [\"Contact_E_Mail_Address\", \"Contact_Phone_Number\"]:\n",
    "    full_modelling_pipeline(each_classifier, second_results_no_sf, sentence_filtering=False, inspect_flow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "1ba07de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Contact                              [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "Contact_E_Mail_Address               [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "Contact_Phone_Number                 [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "Identifier_Cookie_or_similar_Tech    [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "Identifier_Device_ID                 [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "Identifier_IMEI                      [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "Identifier_MAC                       [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "Identifier_Mobile_Carrier            [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "Location                             [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "Location_Cell_Tower                  [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "Location_GPS                         [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "Location_WiFi                        [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "SSO                                  [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "Facebook_SSO                         [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "1st_party                            [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "3rd_party                            [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "PERFORMED                            [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "NOT_PERFORMED                        [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "dtype: object"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_results_no_sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "cf7ef4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the classifiers as the index for our model results df\n",
    "f1s_no_sf = pd.DataFrame(second_results_no_sf, columns=[\"Neg F1\"]).copy()\n",
    "\n",
    "# then populate the dataframe with F1 scores by reference to the 'initial_model_results' series.\n",
    "# the initial_model_results series stores the actual and predicted y-values in the form [model_object, true_y, predicted_y]\n",
    "for index in f1s_no_sf.index:\n",
    "    f1s_no_sf.loc[index, \"Neg F1\"] = f1_score(second_results_no_sf[index][1].copy(), second_results_no_sf[index][2].copy(), pos_label=0)\n",
    "    f1s_no_sf.loc[index, \"Pos F1\"] = f1_score(second_results_no_sf[index][1].copy(), second_results_no_sf[index][2].copy(), pos_label=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "f900c037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_results_no_sf[\"3rd_party\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "67faf41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neg F1</th>\n",
       "      <th>Pos F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Contact</th>\n",
       "      <td>0.954009</td>\n",
       "      <td>0.861678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contact_E_Mail_Address</th>\n",
       "      <td>0.954009</td>\n",
       "      <td>0.861678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contact_Phone_Number</th>\n",
       "      <td>0.954009</td>\n",
       "      <td>0.861678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identifier_Cookie_or_similar_Tech</th>\n",
       "      <td>0.954009</td>\n",
       "      <td>0.861678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identifier_Device_ID</th>\n",
       "      <td>0.954009</td>\n",
       "      <td>0.861678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identifier_IMEI</th>\n",
       "      <td>0.954009</td>\n",
       "      <td>0.861678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identifier_MAC</th>\n",
       "      <td>0.954009</td>\n",
       "      <td>0.861678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identifier_Mobile_Carrier</th>\n",
       "      <td>0.954009</td>\n",
       "      <td>0.861678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>0.954009</td>\n",
       "      <td>0.861678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location_Cell_Tower</th>\n",
       "      <td>0.954009</td>\n",
       "      <td>0.861678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location_GPS</th>\n",
       "      <td>0.954009</td>\n",
       "      <td>0.861678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location_WiFi</th>\n",
       "      <td>0.954009</td>\n",
       "      <td>0.861678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSO</th>\n",
       "      <td>0.954009</td>\n",
       "      <td>0.861678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Facebook_SSO</th>\n",
       "      <td>0.954009</td>\n",
       "      <td>0.861678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st_party</th>\n",
       "      <td>0.954009</td>\n",
       "      <td>0.861678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3rd_party</th>\n",
       "      <td>0.954009</td>\n",
       "      <td>0.861678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERFORMED</th>\n",
       "      <td>0.954009</td>\n",
       "      <td>0.861678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOT_PERFORMED</th>\n",
       "      <td>0.954009</td>\n",
       "      <td>0.861678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Neg F1    Pos F1\n",
       "Contact                            0.954009  0.861678\n",
       "Contact_E_Mail_Address             0.954009  0.861678\n",
       "Contact_Phone_Number               0.954009  0.861678\n",
       "Identifier_Cookie_or_similar_Tech  0.954009  0.861678\n",
       "Identifier_Device_ID               0.954009  0.861678\n",
       "Identifier_IMEI                    0.954009  0.861678\n",
       "Identifier_MAC                     0.954009  0.861678\n",
       "Identifier_Mobile_Carrier          0.954009  0.861678\n",
       "Location                           0.954009  0.861678\n",
       "Location_Cell_Tower                0.954009  0.861678\n",
       "Location_GPS                       0.954009  0.861678\n",
       "Location_WiFi                      0.954009  0.861678\n",
       "SSO                                0.954009  0.861678\n",
       "Facebook_SSO                       0.954009  0.861678\n",
       "1st_party                          0.954009  0.861678\n",
       "3rd_party                          0.954009  0.861678\n",
       "PERFORMED                          0.954009  0.861678\n",
       "NOT_PERFORMED                      0.954009  0.861678"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1s_no_sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ab024623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Contact                               0\n",
       "Contact_E_Mail_Address                1\n",
       "Contact_Phone_Number                  2\n",
       "Identifier_Cookie_or_similar_Tech     3\n",
       "Identifier_Device_ID                  4\n",
       "Identifier_IMEI                       5\n",
       "Identifier_MAC                        6\n",
       "Identifier_Mobile_Carrier             7\n",
       "Location                              8\n",
       "Location_Cell_Tower                   9\n",
       "Location_GPS                         10\n",
       "Location_WiFi                        11\n",
       "SSO                                  12\n",
       "Facebook_SSO                         13\n",
       "1st_party                            14\n",
       "3rd_party                            15\n",
       "PERFORMED                            16\n",
       "NOT_PERFORMED                        17\n",
       "dtype: object"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_results_no_sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "7ee54b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "testingproblem = pd.read_pickle(\"most_recent_model_results.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "836280f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Contact                              [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "Contact_E_Mail_Address               [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "Contact_Phone_Number                 [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "Identifier_Cookie_or_similar_Tech    [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "Identifier_Device_ID                 [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "Identifier_IMEI                      [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "Identifier_MAC                       [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "Identifier_Mobile_Carrier            [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "Location                             [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "Location_Cell_Tower                  [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "Location_GPS                         [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "Location_WiFi                        [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "SSO                                  [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "Facebook_SSO                         [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "1st_party                            [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "3rd_party                            [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "PERFORMED                            [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "NOT_PERFORMED                        [GridSearchCV(cv=5,\\n             estimator=Pi...\n",
       "dtype: object"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testingproblem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "a22a4708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9540085448605177"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(testingproblem[\"Contact_E_Mail_Address\"][1].copy(), testingproblem[\"Contact_E_Mail_Address\"][2].copy(), pos_label=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "priv_pol_nlp",
   "language": "python",
   "name": "priv_pol_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
