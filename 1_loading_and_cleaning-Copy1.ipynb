{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "734024e5",
   "metadata": {},
   "source": [
    "# Loading and Cleaning Data\n",
    "\n",
    "In this notebook I aim to load all the data and manipulate it into a shape that I can then use for EDA and pre-processing.\n",
    "\n",
    "Some functions are custom made for these steps and are imported in the separate python file priv_policy_manipulation_functions.py.  The purpose is to reduce the code length in this notebook.\n",
    "\n",
    "Each annotated privacy policy is stored in YAML format in the file path APP_350_v1_1/annotations/\n",
    "\n",
    "Important terminology: \n",
    "- 'Practice': descriptions of uses of personal data is referred to as a ‘privacy practice’. There are many different 'practices' being analyzed relating to contact information, location, identification, demographics etc.\n",
    "- 'Segment': a segment is roughly equivalent to a paragraph of text data in a privacy policy.\n",
    "- Annotations: each annotation contains the party (1st or 3rd party), the practice, and the modality (performed or not performed).  I will train a classifier to identify each of these.\n",
    "- Targets: something I will be training a classifier to predict; one of the three elements of an annotation\n",
    "\n",
    "The steps are as follows:\n",
    "\n",
    "- Load each policy into a dataframe\n",
    "- Making segments\n",
    "- Extracting list of practices\n",
    "- Applying all annotations to columns\n",
    "- Separate annotations to party and practice\n",
    "- Add target columns for each practice and modality\n",
    "- Tidying\n",
    "\n",
    "Separately: Load crafted features\n",
    "\n",
    "Specifically:\n",
    "1. Load each policy YAML file into a row in a dataframe\n",
    "2. Create additional columns with metadata about each policy. This is for EDA.\n",
    "3. Break the first data frame down further – each segment will be a row in the data frame, while maintaining some of the information around which policy it came from\n",
    "4. Using another file from the APP350 data, load every different data practice annotation. In its initial form, each annotation is a combination the party (1st or 3rd party) with the practice.\n",
    "5. Apply each practice as a column to the data frame (and populate the columns), so that we can see which annotations are applied to each segment. This is useful for further EDA to see the spread of annotations.\n",
    "6. I explore the data a small amount by way of verification and discuss some insights.\n",
    "7. Break the annotations down further to separate the party annotations from the practice annotations. Add these columns to the data frame (and populate these columns)\n",
    "    - This is because I will create separate classifiers for each party and each practice\n",
    "8. Add the modality (‘PERFORMED’ or ‘NOT PERFORMED’) annotations to the dataframe\n",
    "9. Tidying – removing the columns containing a combination of party and practice and reducing to binary\n",
    "\n",
    "Finally: \n",
    "- Loading the crafted features, which will be used for modelling\n",
    "- Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ceb32c",
   "metadata": {},
   "source": [
    "Dataset and features taken from *Natural Language Processing for Mobile App Privacy Compliance. Peter Story, Sebastian Zimmeck, Abhilasha Ravichander, Daniel Smullen, Ziqi Wang, Joel Reidenberg, N. Cameron Russell, and Norman Sadeh. AAAI Spring Symposium on Privacy Enhancing AI and Language Technologies (PAL 2019), Mar 2019.*\n",
    "\n",
    "Available here – APP350: https://usableprivacy.org/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31f7c45",
   "metadata": {},
   "source": [
    "Importing all libraries used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09c92c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "import priv_policy_manipulation_functions as priv_pol_funcs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b562041b",
   "metadata": {},
   "source": [
    "Put the first policy into a pandas DataFrame. I will abbreviate DataFrame as \"df\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a814ec",
   "metadata": {},
   "source": [
    "# Load each policy into a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93e11dd",
   "metadata": {},
   "source": [
    "Calling a function to go into each privacy policy and add it to a row in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78beb882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>policy_id</th>\n",
       "      <th>policy_name</th>\n",
       "      <th>policy_type</th>\n",
       "      <th>contains_synthetic</th>\n",
       "      <th>segments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6677G</td>\n",
       "      <td>TEST</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'segment_id': 0, 'segment_text': 'PRIVACY PO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>AIFactory</td>\n",
       "      <td>TEST</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'segment_id': 0, 'segment_text': 'AI Factory...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>AppliqatoSoftware</td>\n",
       "      <td>TEST</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'segment_id': 0, 'segment_text': 'Automatic ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   policy_id        policy_name policy_type  contains_synthetic  \\\n",
       "0          1              6677G        TEST               False   \n",
       "1          2          AIFactory        TEST               False   \n",
       "2          3  AppliqatoSoftware        TEST               False   \n",
       "\n",
       "                                            segments  \n",
       "0  [{'segment_id': 0, 'segment_text': 'PRIVACY PO...  \n",
       "1  [{'segment_id': 0, 'segment_text': 'AI Factory...  \n",
       "2  [{'segment_id': 0, 'segment_text': 'Automatic ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_policies_df = priv_pol_funcs.load_all_policies()\n",
    "\n",
    "# Demonstrate result\n",
    "display(all_policies_df.head(3)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cea245d",
   "metadata": {},
   "source": [
    "You can see that each policy has information around it's \n",
    "- id, \n",
    "- company name, \n",
    "- whether it falls within the Train/Validate/Test set and \n",
    "- whether it contains synthetic text.\n",
    "- The content and annotations are embedded in column \"segments\"\n",
    "\n",
    "Synthetic text is text added by Story et al. to change segments stating that an action was performed to stating that the action was not performed.  This was done to help train their negative classifier (a classifier to identify that an action was not performed)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03afbf91",
   "metadata": {},
   "source": [
    "Next, calling a function to apply three columns of metadata to the dataframe: \n",
    "- Number of segments in the policy; \n",
    "- number of segments in the policy that contain annotations, and \n",
    "- the total characters in the policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a07bc455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>policy_id</th>\n",
       "      <th>policy_name</th>\n",
       "      <th>policy_type</th>\n",
       "      <th>contains_synthetic</th>\n",
       "      <th>segments</th>\n",
       "      <th>num_segments</th>\n",
       "      <th>num_annotated_segs</th>\n",
       "      <th>total_characters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6677G</td>\n",
       "      <td>TEST</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'segment_id': 0, 'segment_text': 'PRIVACY PO...</td>\n",
       "      <td>36</td>\n",
       "      <td>11</td>\n",
       "      <td>12703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>AIFactory</td>\n",
       "      <td>TEST</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'segment_id': 0, 'segment_text': 'AI Factory...</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>5995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>AppliqatoSoftware</td>\n",
       "      <td>TEST</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'segment_id': 0, 'segment_text': 'Automatic ...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   policy_id        policy_name policy_type  contains_synthetic  \\\n",
       "0          1              6677G        TEST               False   \n",
       "1          2          AIFactory        TEST               False   \n",
       "2          3  AppliqatoSoftware        TEST               False   \n",
       "\n",
       "                                            segments  num_segments  \\\n",
       "0  [{'segment_id': 0, 'segment_text': 'PRIVACY PO...            36   \n",
       "1  [{'segment_id': 0, 'segment_text': 'AI Factory...            14   \n",
       "2  [{'segment_id': 0, 'segment_text': 'Automatic ...             8   \n",
       "\n",
       "   num_annotated_segs  total_characters  \n",
       "0                  11             12703  \n",
       "1                   5              5995  \n",
       "2                   1              2450  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_policies_df = priv_pol_funcs.add_metadata_to_policy_df(all_policies_df)\n",
    "\n",
    "# Demonstrate result\n",
    "display(all_policies_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adf90b5",
   "metadata": {},
   "source": [
    "I know that there are no true duplicates because the function loops through each file by number (1-350).  \n",
    "\n",
    "A further step would be to check that none of the policies are duplicates of each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208c097b",
   "metadata": {},
   "source": [
    "These additional columns allow for some EDA discussed in the next notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7e4abe",
   "metadata": {},
   "source": [
    "# Making segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839b9e7c",
   "metadata": {},
   "source": [
    "Now to make a new dataframe where each row represents a paragraph (segment).  This is effectively breaking the first dataframe down further – each segment will be a row in the dataframe, while maintaining some of the information around which policy it came from.\n",
    "\n",
    "The function works by splitting for a single policy. Then looping through all the policies to apply the same manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c936160",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_policy_number</th>\n",
       "      <th>policy_type</th>\n",
       "      <th>contains_synthetic</th>\n",
       "      <th>policy_segment_id</th>\n",
       "      <th>segment_text</th>\n",
       "      <th>annotations</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>TEST</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>PRIVACY POLICY This privacy policy (hereafter ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>TEST</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1. ABOUT OUR PRODUCTS 1.1 Our products offer a...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>TEST</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2. THE INFORMATION WE COLLECT The information ...</td>\n",
       "      <td>[{'practice': 'Identifier_Cookie_or_similar_Te...</td>\n",
       "      <td>[{'sentence_text': 'IP ADDRESS, COOKIES, AND W...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            source_policy_number policy_type  contains_synthetic  \\\n",
       "segment_id                                                         \n",
       "0                              1        TEST               False   \n",
       "1                              1        TEST               False   \n",
       "2                              1        TEST               False   \n",
       "\n",
       "            policy_segment_id  \\\n",
       "segment_id                      \n",
       "0                           0   \n",
       "1                           1   \n",
       "2                           2   \n",
       "\n",
       "                                                 segment_text  \\\n",
       "segment_id                                                      \n",
       "0           PRIVACY POLICY This privacy policy (hereafter ...   \n",
       "1           1. ABOUT OUR PRODUCTS 1.1 Our products offer a...   \n",
       "2           2. THE INFORMATION WE COLLECT The information ...   \n",
       "\n",
       "                                                  annotations  \\\n",
       "segment_id                                                      \n",
       "0                                                          []   \n",
       "1                                                          []   \n",
       "2           [{'practice': 'Identifier_Cookie_or_similar_Te...   \n",
       "\n",
       "                                                    sentences  \n",
       "segment_id                                                     \n",
       "0                                                          []  \n",
       "1                                                          []  \n",
       "2           [{'sentence_text': 'IP ADDRESS, COOKIES, AND W...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_segments_df = priv_pol_funcs.generate_segment_df(all_policies_df)\n",
    "\n",
    "# Demonstrate the result:\n",
    "display(all_segments_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543e7e5e",
   "metadata": {},
   "source": [
    "Inspecting the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd922f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15543, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_segments_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30902233",
   "metadata": {},
   "source": [
    "Total 15543 segments in the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f736bc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15543 entries, 0 to 15542\n",
      "Data columns (total 7 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   source_policy_number  15543 non-null  int64 \n",
      " 1   policy_type           15543 non-null  object\n",
      " 2   contains_synthetic    15543 non-null  bool  \n",
      " 3   policy_segment_id     15543 non-null  int64 \n",
      " 4   segment_text          15543 non-null  object\n",
      " 5   annotations           15543 non-null  object\n",
      " 6   sentences             15543 non-null  object\n",
      "dtypes: bool(1), int64(2), object(4)\n",
      "memory usage: 743.9+ KB\n"
     ]
    }
   ],
   "source": [
    "all_segments_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594a240d",
   "metadata": {},
   "source": [
    "All policies were pulled through. The data types are appropriate.\n",
    "\n",
    "The data has had some cleaning conducted by Story et al. We see no null values.\n",
    "\n",
    "The entire dataset is only a small file size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5dd646b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.9535 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"{round(sys.getsizeof(all_segments_df)/(1e6),4)} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a791be",
   "metadata": {},
   "source": [
    "### Save as a file – Export the all segments dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3282d7eb",
   "metadata": {},
   "source": [
    "To make it faster to load this dataframe in this notebook and others, I will save it as a pickle file.\n",
    "\n",
    "`pd.to_pickle()` is better than `pd.to_csv()` because:\n",
    "- The stored file size is smaller\n",
    "- List objects in the dataframe are *not* converted to strings, as with csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27287da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_segments_df.to_pickle('objects/all_segments_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f2f7e9",
   "metadata": {},
   "source": [
    "Verifying that the file was correctly saved and can be imported properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78b7a7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "confirm_save_1 = pd.read_pickle('objects/all_segments_df.pkl')\n",
    "print(all_segments_df.shape == confirm_save_1.shape)\n",
    "print(confirm_save_1.equals(all_segments_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c44fa4c",
   "metadata": {},
   "source": [
    "Now the below code can all be ran using the dataframe produced from the pickle file, instead of having to wait for the above code to run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb62815",
   "metadata": {},
   "source": [
    "# Extracting list of practices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a03476",
   "metadata": {},
   "source": [
    "Using another file from the APP350 data, load every different data practice annotation. In its initial form, each annotation is a combination the party (1st or 3rd party) with the practice.\n",
    "\n",
    "Employing my function to get the list of practices from the APP documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0210c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 different groups of practices returned, containing 58 individual practices.\n"
     ]
    }
   ],
   "source": [
    "list_of_practice_groups = priv_pol_funcs.get_list_of_practice_groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f867dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 58 different practices.\n"
     ]
    }
   ],
   "source": [
    "# Expand the list of list with a list comprehension\n",
    "list_of_practices = [practice for practice_group in list_of_practice_groups for practice in practice_group]\n",
    "print(f\"There are {len(list_of_practices)} different practices.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4bae63",
   "metadata": {},
   "source": [
    "Demonstrate the first 5 practices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cf00bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Contact_1stParty',\n",
       " 'Contact_3rdParty',\n",
       " 'Contact_Address_Book_1stParty',\n",
       " 'Contact_Address_Book_3rdParty',\n",
       " 'Contact_City_1stParty']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_practices[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d4666b",
   "metadata": {},
   "source": [
    "Now we can apply these practices to the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cdc593",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d99ae0e",
   "metadata": {},
   "source": [
    "# Applying all annotations to columns in the segment dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ac7490",
   "metadata": {},
   "source": [
    "Now I will apply each practice as a column to the data frame (and populate the columns), so that we can see which annotations are applied to each segment. This is useful for further EDA to see the spread of annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03f6d75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be used to read in the dataframe without running the above code\n",
    "# all_segments_df = pd.read_pickle('objects/all_segments_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de81f257",
   "metadata": {},
   "source": [
    "Using a function to add additional columns to the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "255a9a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the returned dataframe is (15543, 65)\n"
     ]
    }
   ],
   "source": [
    "segment_annotations = priv_pol_funcs.add_empty_annotation_columns(all_segments_df, list_of_practices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ed1f1c",
   "metadata": {},
   "source": [
    "To demonstrate that the columns have been added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "585826f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_policy_number</th>\n",
       "      <th>policy_type</th>\n",
       "      <th>contains_synthetic</th>\n",
       "      <th>policy_segment_id</th>\n",
       "      <th>segment_text</th>\n",
       "      <th>annotations</th>\n",
       "      <th>sentences</th>\n",
       "      <th>Contact_1stParty</th>\n",
       "      <th>Contact_3rdParty</th>\n",
       "      <th>Contact_Address_Book_1stParty</th>\n",
       "      <th>...</th>\n",
       "      <th>Location_Bluetooth_1stParty</th>\n",
       "      <th>Location_Bluetooth_3rdParty</th>\n",
       "      <th>Location_Cell_Tower_1stParty</th>\n",
       "      <th>Location_Cell_Tower_3rdParty</th>\n",
       "      <th>Location_GPS_1stParty</th>\n",
       "      <th>Location_GPS_3rdParty</th>\n",
       "      <th>Location_IP_Address_1stParty</th>\n",
       "      <th>Location_IP_Address_3rdParty</th>\n",
       "      <th>Location_WiFi_1stParty</th>\n",
       "      <th>Location_WiFi_3rdParty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>TEST</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>PRIVACY POLICY This privacy policy (hereafter ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>TEST</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1. ABOUT OUR PRODUCTS 1.1 Our products offer a...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   source_policy_number policy_type  contains_synthetic  policy_segment_id  \\\n",
       "0                     1        TEST               False                  0   \n",
       "1                     1        TEST               False                  1   \n",
       "\n",
       "                                        segment_text annotations sentences  \\\n",
       "0  PRIVACY POLICY This privacy policy (hereafter ...          []        []   \n",
       "1  1. ABOUT OUR PRODUCTS 1.1 Our products offer a...          []        []   \n",
       "\n",
       "   Contact_1stParty  Contact_3rdParty  Contact_Address_Book_1stParty  ...  \\\n",
       "0                 0                 0                              0  ...   \n",
       "1                 0                 0                              0  ...   \n",
       "\n",
       "   Location_Bluetooth_1stParty  Location_Bluetooth_3rdParty  \\\n",
       "0                            0                            0   \n",
       "1                            0                            0   \n",
       "\n",
       "   Location_Cell_Tower_1stParty  Location_Cell_Tower_3rdParty  \\\n",
       "0                             0                             0   \n",
       "1                             0                             0   \n",
       "\n",
       "   Location_GPS_1stParty  Location_GPS_3rdParty  Location_IP_Address_1stParty  \\\n",
       "0                      0                      0                             0   \n",
       "1                      0                      0                             0   \n",
       "\n",
       "   Location_IP_Address_3rdParty  Location_WiFi_1stParty  \\\n",
       "0                             0                       0   \n",
       "1                             0                       0   \n",
       "\n",
       "   Location_WiFi_3rdParty  \n",
       "0                       0  \n",
       "1                       0  \n",
       "\n",
       "[2 rows x 65 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(segment_annotations.head(2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea342bb",
   "metadata": {},
   "source": [
    "Looping through the dataframe, accessing the information within the 'annotations' column to populate the new columns I have created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e237559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate the columns with the annotations\n",
    "for index in range(len(segment_annotations)):\n",
    "    practices_dictionaries = segment_annotations.loc[index, 'annotations']\n",
    "    for each_practice in practices_dictionaries:\n",
    "        segment_annotations.loc[index, each_practice['practice']] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cc8c80",
   "metadata": {},
   "source": [
    "As one verification step I will check that the final row has been annotated (by chance it happens to have annotations so if my annotation columns have value then they have been populated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "217dd145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_annotations.iloc[15542,7:].sum() # columns after 7 cover all annotation columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50a5a02",
   "metadata": {},
   "source": [
    "Total segment annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6055fe7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10215"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_annotations.iloc[:,7:].sum().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5e456c",
   "metadata": {},
   "source": [
    "## Export segment_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2939e23",
   "metadata": {},
   "source": [
    "To make it faster to load this dataframe in this notebook and others, I will save it as a pickle file.  This allows the below code to be ran without waiting for the above code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a45aebf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_annotations.to_pickle('objects/segment_annotations.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8328be6f",
   "metadata": {},
   "source": [
    "Verifying that the file was correctly saved and can be imported properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df8fbecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "confirm_save_2 = pd.read_pickle('objects/segment_annotations.pkl')\n",
    "print(segment_annotations.shape == confirm_save_2.shape)\n",
    "print(confirm_save_2.equals(segment_annotations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f90ac158",
   "metadata": {},
   "outputs": [],
   "source": [
    "confirm_save_2 = pd.read_pickle('objects/segment_annotations.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2c233a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15543, 65)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confirm_save_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1cd3a6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7077411",
   "metadata": {},
   "source": [
    "## Verifying the data loading (with some insights)\n",
    "\n",
    "### Investigating rows with multiple of same annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f50f1c1",
   "metadata": {},
   "source": [
    "It will be interesting to know whether there are any paragraphs with more than one of the same annotation, and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18d7f3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Contact_E_Mail_Address_1stParty    2\n",
       "Location_1stParty                  2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_of_each_annotation_per_paragraph = segment_annotations.iloc[:,7:].max() # creating object to use as filter\n",
    "max_of_each_annotation_per_paragraph.loc[max_of_each_annotation_per_paragraph.values > 1] # filtering using the filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a00aff3",
   "metadata": {},
   "source": [
    "Two annotations were investigated:\n",
    "- Contact_E_Mail_Address_1stParty: only applied twice in one paragraph:\n",
    "    - paragraph 7194: the paragraph mentioned that it both performed AND did not perform this practice.\n",
    "- Location_1stParty: only applied twice in one paragraph:\n",
    "    - paragraph 11150: it is a very long paragraph and has the annotation as both performed and not performed. (I note that the annotated sentences seem questionable.)\n",
    "    \n",
    "Conclusions:\n",
    "- These two occurrences are NOT errors in my data loading\n",
    "- **almost no segments have duplicate annotations.**  This is expected and is a point in favour of the annotators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad3724b",
   "metadata": {},
   "source": [
    "### Investigating annotations that occur very rarely"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dfcfa9",
   "metadata": {},
   "source": [
    "This is another verification step that has general insights for both modelling and app privacy policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebe01bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_segment_frequencies = segment_annotations.iloc[:,7:].sum() # Number of paragraphs with each annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46c5f96",
   "metadata": {},
   "source": [
    "Total annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8222bf75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10215"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_segment_frequencies.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4975aeea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Contact_City_3rdParty             8\n",
       "Identifier_IMSI_3rdParty          3\n",
       "Identifier_SIM_Serial_3rdParty    3\n",
       "Identifier_SSID_BSSID_3rdParty    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_segment_frequencies.loc[annotation_segment_frequencies.values < 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380e7672",
   "metadata": {},
   "source": [
    "The bottom three are ways to identify a user using technical information about the user's system.\n",
    "\n",
    "Some examples:\n",
    "- Contact_City_3rdParty: Tends to be describing a level of abstraction/annonimisation of location data\n",
    "- Identifier_SSID_BSSID_3rdParty: A couple of apps use an advertising service that collects internet network info\n",
    "\n",
    "I am confident that these are not errors because they are rare combinations of data types to collect.\n",
    "\n",
    "We also learn from this that app privacy policies rarely share technical identification information with third parties, or if they do, they fail to document it.  The fact that these annotations are so rare (2/350) lead me to question the relevance of this feature at all, but it does show that apps prefer to identify their users in other ways."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b80367e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4f2d86",
   "metadata": {},
   "source": [
    "# Separate Segment Annotations to party (1st/3rd party) and Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312b0346",
   "metadata": {},
   "source": [
    "Next I will break the annotations down further to separate the party annotations from the practice annotations. (Add these columns to the data frame and populate these columns. This is because I will create separate classifiers for each party and each practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69199fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be used to read in the dataframe without running the above code\n",
    "# segment_annotations = pd.read_pickle('objects/segment_annotations.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f831e07",
   "metadata": {},
   "source": [
    "Reminder of the dataframe at this moment: features segment text and annotations such as \"Contact_Address_Book_1stParty\", as demonstrated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e50fad2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_policy_number</th>\n",
       "      <th>policy_type</th>\n",
       "      <th>contains_synthetic</th>\n",
       "      <th>policy_segment_id</th>\n",
       "      <th>segment_text</th>\n",
       "      <th>annotations</th>\n",
       "      <th>sentences</th>\n",
       "      <th>Contact_1stParty</th>\n",
       "      <th>Contact_3rdParty</th>\n",
       "      <th>Contact_Address_Book_1stParty</th>\n",
       "      <th>...</th>\n",
       "      <th>Location_Bluetooth_1stParty</th>\n",
       "      <th>Location_Bluetooth_3rdParty</th>\n",
       "      <th>Location_Cell_Tower_1stParty</th>\n",
       "      <th>Location_Cell_Tower_3rdParty</th>\n",
       "      <th>Location_GPS_1stParty</th>\n",
       "      <th>Location_GPS_3rdParty</th>\n",
       "      <th>Location_IP_Address_1stParty</th>\n",
       "      <th>Location_IP_Address_3rdParty</th>\n",
       "      <th>Location_WiFi_1stParty</th>\n",
       "      <th>Location_WiFi_3rdParty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>TEST</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>PRIVACY POLICY This privacy policy (hereafter ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>TEST</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1. ABOUT OUR PRODUCTS 1.1 Our products offer a...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>TEST</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2. THE INFORMATION WE COLLECT The information ...</td>\n",
       "      <td>[{'practice': 'Identifier_Cookie_or_similar_Te...</td>\n",
       "      <td>[{'sentence_text': 'IP ADDRESS, COOKIES, AND W...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   source_policy_number policy_type  contains_synthetic  policy_segment_id  \\\n",
       "0                     1        TEST               False                  0   \n",
       "1                     1        TEST               False                  1   \n",
       "2                     1        TEST               False                  2   \n",
       "\n",
       "                                        segment_text  \\\n",
       "0  PRIVACY POLICY This privacy policy (hereafter ...   \n",
       "1  1. ABOUT OUR PRODUCTS 1.1 Our products offer a...   \n",
       "2  2. THE INFORMATION WE COLLECT The information ...   \n",
       "\n",
       "                                         annotations  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2  [{'practice': 'Identifier_Cookie_or_similar_Te...   \n",
       "\n",
       "                                           sentences  Contact_1stParty  \\\n",
       "0                                                 []                 0   \n",
       "1                                                 []                 0   \n",
       "2  [{'sentence_text': 'IP ADDRESS, COOKIES, AND W...                 0   \n",
       "\n",
       "   Contact_3rdParty  Contact_Address_Book_1stParty  ...  \\\n",
       "0                 0                              0  ...   \n",
       "1                 0                              0  ...   \n",
       "2                 0                              0  ...   \n",
       "\n",
       "   Location_Bluetooth_1stParty  Location_Bluetooth_3rdParty  \\\n",
       "0                            0                            0   \n",
       "1                            0                            0   \n",
       "2                            0                            0   \n",
       "\n",
       "   Location_Cell_Tower_1stParty  Location_Cell_Tower_3rdParty  \\\n",
       "0                             0                             0   \n",
       "1                             0                             0   \n",
       "2                             0                             0   \n",
       "\n",
       "   Location_GPS_1stParty  Location_GPS_3rdParty  Location_IP_Address_1stParty  \\\n",
       "0                      0                      0                             0   \n",
       "1                      0                      0                             0   \n",
       "2                      0                      0                             0   \n",
       "\n",
       "   Location_IP_Address_3rdParty  Location_WiFi_1stParty  \\\n",
       "0                             0                       0   \n",
       "1                             0                       0   \n",
       "2                             0                       0   \n",
       "\n",
       "   Location_WiFi_3rdParty  \n",
       "0                       0  \n",
       "1                       0  \n",
       "2                       0  \n",
       "\n",
       "[3 rows x 65 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(segment_annotations.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c3d33c",
   "metadata": {},
   "source": [
    "Adding the party annotations to the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "602f387e",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_annotations[\"1st_party\"] = 0\n",
    "segment_annotations[\"3rd_party\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0711a4fc",
   "metadata": {},
   "source": [
    "Now to populate these columns, I will use the 1st or 3rd party information from the columns I have previously populated.  For each row, if any of the annotations mentioning 1st party have a value, I will populate the '1st party' column (and same for 3rd party).\n",
    "\n",
    "First I will get a list of each annotation mentioning 1st party and a list of each annotation mentioning 3rd party (by reference to the column names of the annotations already added above).\n",
    "\n",
    "Example: the \"Contact_3rdParty\" column is already added, so I will add this column to the list of 3rd parties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62750c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "_1st_party_practices = [column_name for column_name in segment_annotations.columns if \"1stParty\" in column_name]\n",
    "_3rd_party_practices = [column_name for column_name in segment_annotations.columns if \"3rdParty\" in column_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b72b0d",
   "metadata": {},
   "source": [
    "Now I can check for each row, if any of the annotations in the list created above mentioning 1st party have a value, I will populate the new '1st party' column (and same for 3rd party)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "241b017d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for annotation_column in _1st_party_practices:\n",
    "    for index in range(len(segment_annotations.index)):\n",
    "        if segment_annotations.at[index, annotation_column] == 1:\n",
    "            segment_annotations.at[index, \"1st_party\"] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c03b936",
   "metadata": {},
   "outputs": [],
   "source": [
    "for annotation_column in _3rd_party_practices:\n",
    "    for index in range(len(segment_annotations.index)):\n",
    "        if segment_annotations.at[index, annotation_column] == 1:\n",
    "            segment_annotations.at[index, \"3rd_party\"] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b217ce5",
   "metadata": {},
   "source": [
    "Verifying that many were added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "29435698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7536\n",
      "2202\n"
     ]
    }
   ],
   "source": [
    "print(segment_annotations[\"1st_party\"].sum())\n",
    "print(segment_annotations[\"3rd_party\"].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9759812d",
   "metadata": {},
   "source": [
    "I could include the practices 'SSO' and 'Facebook_SSO' to additionally populate the 3rd party practices, since they are both 3rd party by default.  But I'm not going to use these for training the 3rd party classifier, so I don't need to include them, although it is a variable that I should try to change with training the classifier.\n",
    "\n",
    "It means that the total 1st and 3rd party annotation columns will not quite add up to the total annotations we saw earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2db82f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SSO             274\n",
       "Facebook_SSO    199\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_segment_frequencies[['SSO', 'Facebook_SSO']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bf3623",
   "metadata": {},
   "source": [
    "Sanity check: the total 1st party, 3rd party, SSO and Facebook SSO annotations adds up to the total number of annotations seen earlier: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d977d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10215"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_segment_frequencies.sum() # Verify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5b4a00",
   "metadata": {},
   "source": [
    "This looks correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085ae3c8",
   "metadata": {},
   "source": [
    "### Review of further steps to complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec860de3",
   "metadata": {},
   "source": [
    "I am adding each specific annotation type to the dataframe (party/practice/modality). I have just added the 1st and 3rd party annotations to the dataframe.  Further steps:\n",
    "- Add target columns for each practice to all segments\n",
    "- Add target columns for each modality to all segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c1d6bf",
   "metadata": {},
   "source": [
    "# Add target columns for each practice to all segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e5df2d",
   "metadata": {},
   "source": [
    "The method for this will be to:\n",
    "- get a list of each practice to create a column for\n",
    "- add the empty practice columns to the dataframe\n",
    "Currently the dataframe has, for each practice I need, a column for 1st party and 3rd party. e.g. I need to populate the \"Contact_E_Mail_Address\" column using the sum of the values in the Contact_E_Mail_Address_1stParty and Contact_E_Mail_Address_3rdParty. So as a sub-step I will:\n",
    "- make a dictionary where the key is the practice I want to populate and the values are the two 1st and 3rd party versions from which to sum\n",
    "- use this to populate each column\n",
    "- verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69655d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "practice_columns_df = segment_annotations.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e938c3f",
   "metadata": {},
   "source": [
    "Get a list of each practice to create a column for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc3e8ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the practices generated above from features.yaml:\n",
    "the_30_practices = [practice.removesuffix(\"_1stParty\").removesuffix(\"_3rdParty\") for practice in list_of_practices]\n",
    "\n",
    "# remove duplicates:\n",
    "the_30_practices = list(dict.fromkeys(the_30_practices))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804674fc",
   "metadata": {},
   "source": [
    "Don't need to add \"SSO\" and \"Facebook_SSO\" because they were already added, so will remove them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7e3071fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in python, a good way to remove items from a list is to use a list comprehension\n",
    "the_28_practices = [practice for practice in the_30_practices if practice not in [\"SSO\", \"Facebook_SSO\"] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34c1a1c",
   "metadata": {},
   "source": [
    "Add the empty practice columns to the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ba33e9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining the current columns with the new list of columns:\n",
    "practice_columns_df = practice_columns_df.reindex(\n",
    "    columns = practice_columns_df.columns.tolist() + the_28_practices\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d6b873",
   "metadata": {},
   "source": [
    "Make a dictionary where the key is the practice I want to populate and the values are the two 1st and 3rd party versions from which to sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6bfd963a",
   "metadata": {},
   "outputs": [],
   "source": [
    "practice_pair_dict = dict.fromkeys(the_30_practices)\n",
    "\n",
    "for practice in practice_pair_dict.keys():\n",
    "    practice_pair_dict[practice] = [sub_practice for sub_practice in list_of_practices\n",
    "                                    if sub_practice.removesuffix(\"_1stParty\").removesuffix(\"_3rdParty\") == practice]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb51f2e",
   "metadata": {},
   "source": [
    "Populate each practice column:\n",
    "\n",
    "This takes around 4 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "41391e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 16s, sys: 2.1 s, total: 4min 18s\n",
      "Wall time: 4min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# looping through each column name of interest and each row\n",
    "for practice_column in the_28_practices: # only 28 because SSO and Facebook_SSO were populated earlier\n",
    "    for index in range(len(practice_columns_df.index)):\n",
    "        \n",
    "        # assign the value by reference to the above dictionary\n",
    "        practice_columns_df.at[index, practice_column] = practice_columns_df.loc[index, practice_pair_dict[practice_column] ].sum()\n",
    "    \n",
    "    # help see how long is remaining\n",
    "    print(f\"Finished processing {practice_column}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c84be7f",
   "metadata": {},
   "source": [
    "Verification:\n",
    "\n",
    "Checking a single column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "276c9c12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "practice_columns_df[\"Location_Cell_Tower\"].sum() # Verify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf8b2ed",
   "metadata": {},
   "source": [
    "This looks reasonable. Now to check all annotations.\n",
    "\n",
    "As we saw earlier, the total annotations are 10215, so if the sum of the newly added annotations matches, this proves that the correct amount has been added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "37333b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10215.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtering and summing twice to get the total columns and rows of interest\n",
    "_30_practices_filter = practice_columns_df[ the_30_practices ] > 0\n",
    "practice_columns_df[the_30_practices][(_30_practices_filter)].sum().sum() # Verify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1368c20c",
   "metadata": {},
   "source": [
    "It matches! Success!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60952c56",
   "metadata": {},
   "source": [
    "### Export practice_columns_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d92e34",
   "metadata": {},
   "source": [
    "As before, to make it faster to load this dataframe in this notebook and others, I will save it as a pickle file.  This allows the below code to be ran without waiting for the above code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8a01d810",
   "metadata": {},
   "outputs": [],
   "source": [
    "practice_columns_df.to_pickle('objects/practice_columns_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5318ee72",
   "metadata": {},
   "source": [
    "Verifying that the file was correctly saved and can be imported properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d7715748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "confirm_save_3 = pd.read_pickle('objects/practice_columns_df.pkl')\n",
    "print(practice_columns_df.shape == confirm_save_3.shape)\n",
    "print(confirm_save_3.equals(practice_columns_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191a9abf",
   "metadata": {},
   "source": [
    "## Add target columns for each Modality to all segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea03564",
   "metadata": {},
   "source": [
    "Now to add the modality (‘PERFORMED’ or ‘NOT PERFORMED’) annotations to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "124f4e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be used to read in the dataframe without running the above code\n",
    "# practice_columns_df = pd.read_pickle('objects/practice_columns_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "35851d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modality_columns_df = practice_columns_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9c461d",
   "metadata": {},
   "source": [
    "Instantiate empty modality columns to be populated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb8990a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "modality_columns_df[\"PERFORMED\"] = 0\n",
    "modality_columns_df[\"NOT_PERFORMED\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c458592b",
   "metadata": {},
   "source": [
    "Populate the modality columns with the annotations.  This uses a similar process to when initially populating the segments because the modality is stored at the same level in the YAML structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3d0296ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(modality_columns_df)):\n",
    "    practices_dictionaries = modality_columns_df.at[index, 'annotations']\n",
    "    for each_practice in practices_dictionaries:\n",
    "        modality_columns_df.at[index, each_practice['modality']] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bdaa8f",
   "metadata": {},
   "source": [
    "Verification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bfdd94eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8205"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modality_columns_df[\"PERFORMED\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8e03f352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2010"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modality_columns_df[\"NOT_PERFORMED\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cb3622",
   "metadata": {},
   "source": [
    "Once again, these add up to the total annotations seen earlier of 10215, which is a helpful verification.\n",
    "\n",
    "We also see that there are not as many annotations stating that the practice is not performed. The implication is that  Privacy policies tend to only state what they are doing, and rarely add extra clarity by stating what they are not doing.  Remember that most of these NOT_PERFORMED annotations were added synthetically so the true number would be much less.\n",
    "\n",
    "To review, the columns now are:\n",
    "- columns about the policy e.g. whether it is train/validate/test; \n",
    "- each segment; \n",
    "- columns for concatenated annotations (of the form practice_party), \n",
    "- columns for each element of annotation:\n",
    "    - party (two columns: either 1st party or 3rd party)\n",
    "    - practice (30 columns)\n",
    "    - modality (two columns: either Performed or Not Performed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9c0f50b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all columns can be seen using:\n",
    "# modality_columns_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f9af1f",
   "metadata": {},
   "source": [
    "Since we now have a dataframe at the segment level with columns for each combination of annotations and columns for the specific annotations of practice, party and modality, I will name this `segment_all_targets_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6deec0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_all_targets_df = modality_columns_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afcf1b0",
   "metadata": {},
   "source": [
    "**Next:**\n",
    "\n",
    "I will now remove some columns to create a new dataframe where the only target columns correspond to the specific annotations for a specific practice, the party and modality.  I will also change the target columns to be binary instead of a sum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862204f3",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0736bd7e",
   "metadata": {},
   "source": [
    "# Tidying\n",
    "\n",
    "## Remove columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3a93e8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_annots_df = segment_all_targets_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf06a09",
   "metadata": {},
   "source": [
    "The `list_of_practices` has all 58 concatenated annotations (the *practice* concatenated with whether it's *1st or 3rd party*), but two in this list (\"SSO\" and \"Facebook_SSO\") are 3rd party by default. We need to remove all the concatenated annotations from the current dataframe, except for those two, since they are already in the correct form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dce09ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "the_56_specific_practices = [practice for practice in list_of_practices if practice not in [\"SSO\", \"Facebook_SSO\"] ]\n",
    "segment_annots_df = segment_annots_df.drop(columns = the_56_specific_practices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766d748a",
   "metadata": {},
   "source": [
    "Verify columns have been dropped and we now have the correct number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "546c1fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15543, 41)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_annots_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5fc11425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15543, 34)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_annots_df.loc[:,'SSO':].shape # target columns are all those that happen to be including and after \"SSO\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa86069",
   "metadata": {},
   "source": [
    "There are 34 different 'target' columns ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bb04d128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns can be further inspected using:\n",
    "# segment_annots_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96abd423",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e31e04f",
   "metadata": {},
   "source": [
    "## Convert to binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d307e6",
   "metadata": {},
   "source": [
    "Previously the columns were populated with the frequency of each annotation, which was helpful for EDA to see insights. But for modelling each column must be binary, otherwise the data does not fairly represent binary classification (target classes of 0 or 1)\n",
    "\n",
    "I will be reducing the numbers above 1 down to one.  One verification step is to check that the number of cells with and above zero do not change, so first I will note these numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4c8afa6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 510617 cells with 0\n",
      "There are 17845 cells above 0\n"
     ]
    }
   ],
   "source": [
    "# number of cells greater than 0 should not change\n",
    "print(f\"There are {(segment_annots_df.loc[:,'SSO':] == 0).sum().sum()} cells with 0\")\n",
    "print(f\"There are {(segment_annots_df.loc[:,'SSO':] > 0).sum().sum()} cells above 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4091b7f1",
   "metadata": {},
   "source": [
    "Reducing the numbers above 1 down to one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ac54a355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.08 s, sys: 15.3 ms, total: 2.09 s\n",
      "Wall time: 2.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# For each column from SSO onwards, go into every cell, and if it's above 1, set it to 1.\n",
    "\n",
    "for column in segment_annots_df.loc[:,'SSO':].columns:\n",
    "    for i in range(len(segment_annots_df[column])):\n",
    "\n",
    "        if segment_annots_df.at[i, column] > 1:\n",
    "            segment_annots_df.at[i, column] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae36b7be",
   "metadata": {},
   "source": [
    "Verification: \n",
    "\n",
    "The number of cells greater than 0 should be same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1a551fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 510617 cells with 0\n",
      "There are 17845 cells above 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {(segment_annots_df.loc[:,'SSO':] == 0).sum().sum()} cells with 0\")\n",
    "print(f\"There are {(segment_annots_df.loc[:,'SSO':] > 0).sum().sum()} cells above 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d149a8a5",
   "metadata": {},
   "source": [
    "Should now be no target cells with more than 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1bcac6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_annots_df.loc[:,'SSO':].max().max() # shows the max value from all target columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319e9c4d",
   "metadata": {},
   "source": [
    "### Save to pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e5114a",
   "metadata": {},
   "source": [
    "As before, to make it faster to load this dataframe in this notebook and others, I will save this dataframe as a pickle file.  This allows the below code to be ran without waiting for the above code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5a397a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_annots_df.to_pickle('objects/segment_annots_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3dee05",
   "metadata": {},
   "source": [
    "Verifying that the file was correctly saved and can be imported properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2ae3db96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "confirm_save_4 = pd.read_pickle('objects/segment_annots_df.pkl')\n",
    "print(segment_annots_df.shape == confirm_save_4.shape)\n",
    "print(confirm_save_4.equals(segment_annots_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605c512b",
   "metadata": {},
   "source": [
    "This above dataframe now has the granularity and target columns required to run a baseline model using only text vectorization, but in a later notebook I will conduct the same preprocessing steps as done by Usable Privacy.org in the paper to create additional dataframes to use for modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc15770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "finding_location_sentence = pd.read_pickle('objects/segment_annots_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b97d0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['source_policy_number', 'policy_type', 'contains_synthetic',\n",
       "       'policy_segment_id', 'segment_text', 'annotations', 'sentences', 'SSO',\n",
       "       'Facebook_SSO', '1st_party', '3rd_party', 'Contact',\n",
       "       'Contact_Address_Book', 'Contact_City', 'Contact_E_Mail_Address',\n",
       "       'Contact_Password', 'Contact_Phone_Number', 'Contact_Postal_Address',\n",
       "       'Contact_ZIP', 'Demographic', 'Demographic_Age', 'Demographic_Gender',\n",
       "       'Identifier', 'Identifier_Ad_ID', 'Identifier_Cookie_or_similar_Tech',\n",
       "       'Identifier_Device_ID', 'Identifier_IMEI', 'Identifier_IMSI',\n",
       "       'Identifier_IP_Address', 'Identifier_MAC', 'Identifier_Mobile_Carrier',\n",
       "       'Identifier_SIM_Serial', 'Identifier_SSID_BSSID', 'Location',\n",
       "       'Location_Bluetooth', 'Location_Cell_Tower', 'Location_GPS',\n",
       "       'Location_IP_Address', 'Location_WiFi', 'PERFORMED', 'NOT_PERFORMED'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finding_location_sentence.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "720318ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_df = finding_location_sentence[(finding_location_sentence['Location_GPS'] == 1) & (finding_location_sentence['contains_synthetic'] == False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e0a6e7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_text</th>\n",
       "      <th>Location_GPS</th>\n",
       "      <th>contains_synthetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7211</th>\n",
       "      <td>Geolocation. We can collect your unique user i...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4484</th>\n",
       "      <td>Read More We may sponsor contests, challenges,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>Precise Device Location Tracking.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Some of BANDAI NAMCO's mobile applications may...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8409</th>\n",
       "      <td>(4)Location Data. When you have enabled geogra...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>g) Location information: When you use BlackBer...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>If you authorized us and/or our service provid...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7167</th>\n",
       "      <td>Location information - we collect information ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7584</th>\n",
       "      <td>We do not ask you for, access or track any pre...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8170</th>\n",
       "      <td>Notwithstanding anything else in this policy, ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           segment_text  Location_GPS  \\\n",
       "7211  Geolocation. We can collect your unique user i...           1.0   \n",
       "4484  Read More We may sponsor contests, challenges,...           1.0   \n",
       "6494                  Precise Device Location Tracking.           1.0   \n",
       "115   Some of BANDAI NAMCO's mobile applications may...           1.0   \n",
       "8409  (4)Location Data. When you have enabled geogra...           1.0   \n",
       "202   g) Location information: When you use BlackBer...           1.0   \n",
       "6495  If you authorized us and/or our service provid...           1.0   \n",
       "7167  Location information - we collect information ...           1.0   \n",
       "7584  We do not ask you for, access or track any pre...           1.0   \n",
       "8170  Notwithstanding anything else in this policy, ...           1.0   \n",
       "\n",
       "      contains_synthetic  \n",
       "7211               False  \n",
       "4484               False  \n",
       "6494               False  \n",
       "115                False  \n",
       "8409               False  \n",
       "202                False  \n",
       "6495               False  \n",
       "7167               False  \n",
       "7584               False  \n",
       "8170               False  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_df[['segment_text','Location_GPS', 'contains_synthetic']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "69d928bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(4)Location Data. When you have enabled geographical location-based or GPS services on your device in relation to Our Services, we will collect information about your geographical location or GPS position based on the location of the device you are using to access our Services. That information helps us identify your physical location. Please note that we will not store or transfer your GPS information nor do we use such information to specify you.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_df[['segment_text','Location_GPS']].loc[8409,'segment_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23129fd",
   "metadata": {},
   "source": [
    "# Load crafted features for each target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd20013",
   "metadata": {},
   "source": [
    "To help to create accurate classifiers, columns will be added to the dataframe that contain key phrases that may be found in segment that has been annotated with a specific annotation. For example, the phrases 'phone book', 'phonebook' or 'address book' could be found in segments that have been annotated with the *Contact_Address_Book* annotation and adding these phrases as columns could help a classifier to correctly identify *Contact_Address_Book*.\n",
    "\n",
    "Story et al. created these features based on their expertise and findings across the train and validation policies and have made them available along with the data.\n",
    "\n",
    "These will be used as 'crafted feature' columns and for 'sentence filtering' when modelling.  (Along with adding the crafted feature columns, 'Sentence filtering' is another preprocessing step that Story et al. found can improve the performance of some classifiers and will be explained in my Modelling Pipeline notebook.)\n",
    "\n",
    "The form that I want all the features in is a dataframe with a column with each target and another with a list of the crafted features related to it.  The format it is initially in is a YAML file with the crafted features being nested under each target.\n",
    "\n",
    "This first function loads a list of each crafted feature for all of the *practices*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2443fd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if running this section of the notebook by itself, you will need to also run these lines of code from above:\n",
    "\n",
    "# list_of_practice_groups = priv_pol_funcs.get_list_of_practice_groups()\n",
    "# list_of_practices = [practice for practice_group in list_of_practice_groups for practice in practice_group]\n",
    "# the_30_practices = [practice.removesuffix(\"_1stParty\").removesuffix(\"_3rdParty\") for practice in list_of_practices]\n",
    "# the_30_practices = list(dict.fromkeys(the_30_practices))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ff83da",
   "metadata": {},
   "source": [
    "Demonstrating the function by returning just the first two lists of crafted features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1e7057ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 different groups of features returned, containing 354 individual features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['city', 'hometown'],\n",
       " ['e-mail address',\n",
       "  'email address',\n",
       "  'e-mail and mailing address',\n",
       "  'email and mailing address',\n",
       "  'e-mail or mailing address',\n",
       "  'email or mailing address']]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priv_pol_funcs.get_features_for_practices()[2:4] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94455783",
   "metadata": {},
   "source": [
    "Ultimately I will add each of these individual features to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7134ab66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 different groups of features returned, containing 354 individual features.\n"
     ]
    }
   ],
   "source": [
    "features_for_practices = priv_pol_funcs.get_features_for_practices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75b10eb",
   "metadata": {},
   "source": [
    "Creating the dataframe from the list of practices.\n",
    "\n",
    "The crafted features for 'SSO' are the same as for 'facebook_SSO' so I don't need 'SSO'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0e3e26a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "the_29_practices = [practice for practice in the_30_practices if practice != \"SSO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dc5dae4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "practice_and_created_features = pd.DataFrame(data = [the_29_practices, features_for_practices]).T\n",
    "practice_and_created_features.columns = [\"practice\", \"features\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eda306",
   "metadata": {},
   "source": [
    "Manually adding the features for SSO to the end of the dataframe by manually looking up the index of Facebook SSO to use.\n",
    "\n",
    "Author's note: I'm not sure why I had to add SSO separately, nor why I did it by manual hard coding instead of programatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "44ebc32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "practice_and_created_features.at[len(practice_and_created_features),\"practice\"] = \"SSO\"\n",
    "practice_and_created_features.at[29,\"features\"] = practice_and_created_features.at[11,\"features\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925a3582",
   "metadata": {},
   "source": [
    "Demonstrating the resulting dataframe containing each practice and its crafted features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3a7ad650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>practice</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Contact</td>\n",
       "      <td>[contact info, contact details, contact data, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contact_Address_Book</td>\n",
       "      <td>[phone book, phonebook, contact information in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Contact_City</td>\n",
       "      <td>[city, hometown]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               practice                                           features\n",
       "0               Contact  [contact info, contact details, contact data, ...\n",
       "1  Contact_Address_Book  [phone book, phonebook, contact information in...\n",
       "2          Contact_City                                   [city, hometown]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "practice_and_created_features.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0674c262",
   "metadata": {},
   "source": [
    "Now I need to grab the features for the other targets (parties and modalities) too, which are also stored in the 'features.yml' file. They are stored near the top of the YAML structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2debfb8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_types</th>\n",
       "      <th>modalities.PERFORMED</th>\n",
       "      <th>modalities.NOT_PERFORMED</th>\n",
       "      <th>parties.FirstParty</th>\n",
       "      <th>parties.ThirdParty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'practices': ['Contact_1stParty', 'Contact_3...</td>\n",
       "      <td>[consent, permission,  opt, collect, access, g...</td>\n",
       "      <td>[not collect, no longer collect, not access, n...</td>\n",
       "      <td>[ we ,  you ,  us ,  our , the app, the software]</td>\n",
       "      <td>[partner, third part, third-part, service prov...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          data_types  \\\n",
       "0  [{'practices': ['Contact_1stParty', 'Contact_3...   \n",
       "\n",
       "                                modalities.PERFORMED  \\\n",
       "0  [consent, permission,  opt, collect, access, g...   \n",
       "\n",
       "                            modalities.NOT_PERFORMED  \\\n",
       "0  [not collect, no longer collect, not access, n...   \n",
       "\n",
       "                                  parties.FirstParty  \\\n",
       "0  [ we ,  you ,  us ,  our , the app, the software]   \n",
       "\n",
       "                                  parties.ThirdParty  \n",
       "0  [partner, third part, third-part, service prov...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"APP_350_v1_1/features.yml\", \"r\") as stream:\n",
    "    try:\n",
    "        features_yml = (json_normalize(yaml.safe_load(stream)))\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "features_yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321d3507",
   "metadata": {},
   "source": [
    "Adding these targets to the dataframe.  I make them into a list of lists, then make this into a new dataframe, then concatenate it with the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ef1baa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_to_df = [\n",
    "['1st_party', features_yml.loc[0,\"parties.FirstParty\"] ],\n",
    "['3rd_party', features_yml.loc[0,\"parties.ThirdParty\"] ],\n",
    "['PERFORMED', features_yml.loc[0,\"modalities.PERFORMED\"] ],\n",
    "['NOT_PERFORMED', features_yml.loc[0,\"modalities.NOT_PERFORMED\"] ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a705fc88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "annotation_features = pd.concat( [practice_and_created_features, \n",
    "                                  pd.DataFrame(add_to_df, columns=['practice', 'features'])],\n",
    "           axis = 0,\n",
    "           ignore_index = True)\n",
    "annotation_features.columns = ['annotation', 'features']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513bcaab",
   "metadata": {},
   "source": [
    "Verifying that all the new targets have been added at the end of the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6c0117cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Location_WiFi</td>\n",
       "      <td>[wifi signal, wifi access point, wifi location...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SSO</td>\n",
       "      <td>[login credentials from one of your accounts, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1st_party</td>\n",
       "      <td>[ we ,  you ,  us ,  our , the app, the software]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3rd_party</td>\n",
       "      <td>[partner, third part, third-part, service prov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>PERFORMED</td>\n",
       "      <td>[consent, permission,  opt, collect, access, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NOT_PERFORMED</td>\n",
       "      <td>[not collect, no longer collect, not access, n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       annotation                                           features\n",
       "28  Location_WiFi  [wifi signal, wifi access point, wifi location...\n",
       "29            SSO  [login credentials from one of your accounts, ...\n",
       "30      1st_party  [ we ,  you ,  us ,  our , the app, the software]\n",
       "31      3rd_party  [partner, third part, third-part, service prov...\n",
       "32      PERFORMED  [consent, permission,  opt, collect, access, g...\n",
       "33  NOT_PERFORMED  [not collect, no longer collect, not access, n..."
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_features.tail(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda64aaa",
   "metadata": {},
   "source": [
    "Saving the file for use in other notebooks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ef6aa7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_features.to_pickle('objects/annotation_features.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a28c5c",
   "metadata": {},
   "source": [
    "Verifying that the file was correctly saved and can be imported properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8896dcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "confirm_save_6 = pd.read_pickle('objects/annotation_features.pkl')\n",
    "print(annotation_features.shape == confirm_save_6.shape)\n",
    "print(confirm_save_6.equals(annotation_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db11c746",
   "metadata": {},
   "source": [
    "So now I have a dataframe with all the different annotations and a list of their respective crafted features called \"annotation_features\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0a0044",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76762bb",
   "metadata": {},
   "source": [
    "I now have a range of dataframes that I can use for EDA and modelling.\n",
    "\n",
    "Those dataframes are listed here:\n",
    "\n",
    "**Dataframes (DF):**<br>\n",
    "“Initial DF – “all_segments_df” – contains policy metadata, segment text, and YAML-embedded annotations and sentences\n",
    "\n",
    "DF 2 – “segment_annotations” – all the above plus columns for annotations of the form [data_practice, party] (58 additional columns)\n",
    "\n",
    "DF 3 – “practice_columns_df” – as above with the addition of columns for annotations for each data practice (30 additional columns). Suitable for EDA (not modelling) since it counts number of occurrences of each practice in each segment.\n",
    "\n",
    "DF 4 – \"segment_annots_df\" – As with the first data frame and with the 30 columns added to the above Dataframe.  Essentially it features each segment and the targets. Suitable for modelling because each practice is binary (present or not)\n",
    "\n",
    "Another dataframe listing each Crafted Feature for each annotation – \"annotation_features\"\n",
    "\n",
    "In the pre-processing notebook, the next dataframe to make will be DF 5 – \"crafted_features_df\" – Same as DF 4 but with Crafted Featured added. So it will contain each segment, all crafted features, and columns for targets of practice, parties and modality."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "priv_pol_nlp",
   "language": "python",
   "name": "priv_pol_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
